{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasilis-Kyriakopoulos/Finetune-LLM-/blob/main/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61cd394d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2bb60b268c3e43cda402c8025694f047",
            "59456630863f47d0a2e9a9501fe5e0c0",
            "a653da5d099a4d2e9ab321a502696715",
            "0e896eb89da1475d8550f90a03c36442",
            "ed38f0951dd3497da6e36e294ec2c880",
            "f0a19b53da804d4b8b8457c8ce17351e",
            "f55f84e0999740649d5f177be2bf06ea",
            "d60fe2c0871344828b004a0ca035f233",
            "33745e90c34c497b94fbd995fd47696e",
            "bc447e673bdc46de8f71f003cd30a914",
            "be28821e0f0241079aa0220411328584",
            "1cd40e349b734d60a5b760bf1232ba08",
            "30f6ac4276f547d0913b9b59ebe6bb69",
            "3dc7f099bc69445fbd15e66731ca254c",
            "5b21f33677794182a9d93ba8ebeb87cd",
            "f5e05c7e75b9476688eaf110de279cc3",
            "76f78b24e1324ae199e4d294a9928a61",
            "aa08721eaf914e628c9a9c3889ae8ae5",
            "cf46190f9d2542789096244ff9f159c4",
            "15ba200bada44afebfce411f0a08aa51",
            "de406d179c134a649395ac4b5c5e9f07",
            "c57e18d56dde4a28a7f54e9bf8a44c6b"
          ]
        },
        "id": "61cd394d",
        "outputId": "985f29ca-56df-465b-ec6d-b35f5353da74"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bb60b268c3e43cda402c8025694f047"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "train.csv:   0%|          | 0.00/1.05G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd40e349b734d60a5b760bf1232ba08"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "ds = load_dataset(\"maxscha/commitbench\")\n",
        "main_path = \"/content/drive/MyDrive/FinetuneLLM_Ergasia/\"\n",
        "\n",
        "cols = [\"diff\", \"message\"]\n",
        "\n",
        "\n",
        "ds[\"train\"].select_columns(cols) \\\n",
        "    .to_pandas() \\\n",
        "    .to_csv(main_path+\"commitbench_train.csv\", index=False)\n",
        "\n",
        "\n",
        "ds[\"validation\"].select_columns(cols) \\\n",
        "    .to_pandas() \\\n",
        "    .to_csv(main_path+\"commitbench_validation.csv\",index=False)\n",
        "\n",
        "\n",
        "ds[\"test\"].select_columns(cols) \\\n",
        "    .to_pandas() \\\n",
        "    .to_csv(main_path+\"commitbench_test.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "main_path = \"/content/drive/MyDrive/FinetuneLLM_Ergasia/\"\n",
        "train_df = pd.read_csv(main_path + \"commitbench_train_1pct.csv\")\n",
        "val_df = pd.read_csv(main_path + \"commitbench_validation_1pct.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTR0NtL4Lfd8",
        "outputId": "bfa7f987-f3ac-4d78-aed8-b98cfd80934f"
      },
      "id": "gTR0NtL4Lfd8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b70bb305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "b70bb305",
        "outputId": "cca40dc9-3682-4465-f86f-6d7594e10948"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4152985399.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0msampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1843\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1844\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1845\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1983\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1985\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1986\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1921\u001b[0m                     \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1922\u001b[0m                     \u001b[0mcol_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1924\u001b[0m                     \u001b[0mnrows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1925\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36mgetstate\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "input_csv = main_path + \"commitbench_validation.csv\"\n",
        "output_csv = main_path + \"commitbench_validation_1pct.csv\"\n",
        "\n",
        "chunk_size = 100_000\n",
        "keep_frac = 0.01\n",
        "first = True\n",
        "\n",
        "for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
        "    sampled = chunk.sample(frac=keep_frac, random_state=42)\n",
        "\n",
        "    sampled.to_csv(\n",
        "        output_csv,\n",
        "        mode=\"a\",\n",
        "        index=False,\n",
        "        header=first\n",
        "    )\n",
        "    first = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcf47e27",
      "metadata": {
        "id": "dcf47e27"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "DHsGmVCtOuXn",
        "outputId": "a9ae21cc-b962-42cc-f725-993edcaf1499"
      },
      "id": "DHsGmVCtOuXn",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                diff  \\\n",
              "0  diff --git a/lib/is_translatable.rb b/lib/is_t...   \n",
              "1  diff --git a/src/Event.php b/src/Event.php\\nin...   \n",
              "2  diff --git a/templates/module/modularity-mod-s...   \n",
              "3  diff --git a/src/FieldHandlers/BaseFileFieldHa...   \n",
              "4  diff --git a/bids/layout/tests/test_layout.py ...   \n",
              "\n",
              "                                             message  \n",
              "0  Adding some failing specs to get the translati...  \n",
              "1             Added getDescription function to Event  \n",
              "2  Dont initialize slider if column count is same...  \n",
              "3  letting the user open a file in the new tab (t...  \n",
              "4  TEST: Test upward propagation of dynamic gette...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9dad708-92f0-40a9-a45f-1d8e777ab32f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>diff --git a/lib/is_translatable.rb b/lib/is_t...</td>\n",
              "      <td>Adding some failing specs to get the translati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diff --git a/src/Event.php b/src/Event.php\\nin...</td>\n",
              "      <td>Added getDescription function to Event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>diff --git a/templates/module/modularity-mod-s...</td>\n",
              "      <td>Dont initialize slider if column count is same...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diff --git a/src/FieldHandlers/BaseFileFieldHa...</td>\n",
              "      <td>letting the user open a file in the new tab (t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diff --git a/bids/layout/tests/test_layout.py ...</td>\n",
              "      <td>TEST: Test upward propagation of dynamic gette...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9dad708-92f0-40a9-a45f-1d8e777ab32f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9dad708-92f0-40a9-a45f-1d8e777ab32f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9dad708-92f0-40a9-a45f-1d8e777ab32f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 12653,\n  \"fields\": [\n    {\n      \"column\": \"diff\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11653,\n        \"samples\": [\n          \"diff --git a/test/index.js b/test/index.js\\nindex <HASH>..<HASH> 100644\\n--- a/test/index.js\\n+++ b/test/index.js\\n@@ -21,7 +21,7 @@ describe('eslint-plugin-mocha', function () {\\n         ruleFiles.forEach(function (file) {\\n             var ruleName = path.basename(file, '.js');\\n \\n-            expect(plugin).to.have.deep.property('rules.' + ruleName)\\n+            expect(plugin).to.have.nested.property('rules.' + ruleName)\\n                 .that.equals(require(rulesDir + ruleName));\\n         });\\n     });\",\n          \"diff --git a/src/Illuminate/Support/Pluralizer.php b/src/Illuminate/Support/Pluralizer.php\\nindex <HASH>..<HASH> 100755\\n--- a/src/Illuminate/Support/Pluralizer.php\\n+++ b/src/Illuminate/Support/Pluralizer.php\\n@@ -73,7 +73,7 @@ class Pluralizer {\\n \\t */\\n \\tpublic static $irregular = array(\\n \\t\\t'child' => 'children',\\n-        'criterion' => 'criteria',\\n+\\t\\t'criterion' => 'criteria',\\n \\t\\t'foot' => 'feet',\\n \\t\\t'freshman' => 'freshmen',\\n \\t\\t'goose' => 'geese',\",\n          \"diff --git a/src/TQ/Git/Cli/CallResult.php b/src/TQ/Git/Cli/CallResult.php\\nindex <HASH>..<HASH> 100644\\n--- a/src/TQ/Git/Cli/CallResult.php\\n+++ b/src/TQ/Git/Cli/CallResult.php\\n@@ -95,7 +95,7 @@ class CallResult\\n      *\\n      * @return Call\\n      */\\n-    public function cliCall()\\n+    public function getCliCall()\\n     {\\n         return $this->cliCall;\\n     }\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11568,\n        \"samples\": [\n          \"fix test, dependencies changed because of CallOnContentReady changes\",\n          \"Translate the connection timed out error\",\n          \"Fix offset fetch when partitions are manually assigned (#<I>)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "hMdTmrknPg1m",
        "outputId": "e7ddae5a-eebe-4101-e3e0-116ee5fb3a3e"
      },
      "id": "hMdTmrknPg1m",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                diff  \\\n",
              "0  diff --git a/lib/dicom/anonymizer.rb b/lib/dic...   \n",
              "1  diff --git a/comments-bundle/contao/Comments.p...   \n",
              "2  diff --git a/src/MetaBox.php b/src/MetaBox.php...   \n",
              "3  diff --git a/header.js b/header.js\\nindex <HAS...   \n",
              "4  diff --git a/taskw/warrior.py b/taskw/warrior....   \n",
              "\n",
              "                                             message  \n",
              "0                     Added Anonymizer#to_anonymizer  \n",
              "1  [Comments] Do not allow insert tags in comment...  \n",
              "2  Use specific types annotations for arrays in d...  \n",
              "3                           Fix lint, rlp isn't used  \n",
              "4  Merge the \"waiting\" list back into the \"pendin...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dcb2829b-df70-4c48-9779-5c83f7fa44c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>diff --git a/lib/dicom/anonymizer.rb b/lib/dic...</td>\n",
              "      <td>Added Anonymizer#to_anonymizer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diff --git a/comments-bundle/contao/Comments.p...</td>\n",
              "      <td>[Comments] Do not allow insert tags in comment...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>diff --git a/src/MetaBox.php b/src/MetaBox.php...</td>\n",
              "      <td>Use specific types annotations for arrays in d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diff --git a/header.js b/header.js\\nindex &lt;HAS...</td>\n",
              "      <td>Fix lint, rlp isn't used</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diff --git a/taskw/warrior.py b/taskw/warrior....</td>\n",
              "      <td>Merge the \"waiting\" list back into the \"pendin...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dcb2829b-df70-4c48-9779-5c83f7fa44c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dcb2829b-df70-4c48-9779-5c83f7fa44c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dcb2829b-df70-4c48-9779-5c83f7fa44c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_df",
              "summary": "{\n  \"name\": \"val_df\",\n  \"rows\": 2497,\n  \"fields\": [\n    {\n      \"column\": \"diff\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2497,\n        \"samples\": [\n          \"diff --git a/lib/fastlane/setup.rb b/lib/fastlane/setup.rb\\nindex <HASH>..<HASH> 100644\\n--- a/lib/fastlane/setup.rb\\n+++ b/lib/fastlane/setup.rb\\n@@ -93,6 +93,14 @@ module Fastlane\\n         end\\n       end\\n \\n+      if @tools[:snapshot] and @tools[:deliver]\\n+        # Deliver is already installed\\n+        Helper.log.info \\\"The 'screenshots' folder inside the 'deliver' folder will not be used.\\\".yellow\\n+        Helper.log.info \\\"Instead the 'screenshots' folder inside the 'fastlane' folder will be used.\\\".yellow\\n+        Helper.log.info \\\"Click Enter to confirm\\\".green\\n+        gets\\n+      end\\n+\\n       if agree(\\\"Do you want to use 'sigh', which will maintain and download the provisioning profile for your app? (y/n)\\\".yellow, true)\\n         @tools[:sigh] = true\\n       end\",\n          \"diff --git a/lib/papageorge/gui.py b/lib/papageorge/gui.py\\nindex <HASH>..<HASH> 100644\\n--- a/lib/papageorge/gui.py\\n+++ b/lib/papageorge/gui.py\\n@@ -387,6 +387,7 @@ class BoardCommandsPopover(Gtk.Popover):\\n                 for label, command in [\\n                         ('_Examine Last', lambda x : 'exl'),\\n                         ('_Rematch', lambda x : 'rematch'),\\n+                        ('_Say Good Game!', lambda x : 'say Good Game!'),\\n                         ]:\\n                     button = Gtk.Button.new_with_mnemonic(label)\\n                     button.command = command\",\n          \"diff --git a/display/renderbasic/src/main/java/org/openscience/cdk/renderer/generators/standard/StandardGenerator.java b/display/renderbasic/src/main/java/org/openscience/cdk/renderer/generators/standard/StandardGenerator.java\\nindex <HASH>..<HASH> 100644\\n--- a/display/renderbasic/src/main/java/org/openscience/cdk/renderer/generators/standard/StandardGenerator.java\\n+++ b/display/renderbasic/src/main/java/org/openscience/cdk/renderer/generators/standard/StandardGenerator.java\\n@@ -378,7 +378,7 @@ public final class StandardGenerator implements IGenerator<IAtomContainer> {\\n \\n                     // defines how the element is aligned on the atom point, when\\n                     // aligned to the left, the first character 'e.g. Cl' is used.\\n-                    if (visNeighbors.size() > 0) {\\n+                    if (visNeighbors.size() < 4) {\\n                         if (hPosition == Left) {\\n                             symbols[i] = symbols[i].alignTo(AtomSymbol.SymbolAlignment.Right);\\n                         } else {\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"message\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2490,\n        \"samples\": [\n          \"Fixing reassigning previous `first.left` from an update in `set()`\",\n          \"Updated to <I> version\",\n          \"this is redundant as launcher always record what it launches.\\n\\n\\ngit-svn-id: <URL>\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b204b51a",
      "metadata": {
        "id": "b204b51a"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c66a30e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "c66a30e5",
        "outputId": "f55b420d-2e26-459f-edb3-7abf0c0f48ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'format_input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-539593372.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_rng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0msample_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50_000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msample_texts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'format_input' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "def token_len(t: str) -> int:\n",
        "    return len(tokenizer.encode(t, add_special_tokens=True))\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "texts = train_df.apply(format_input, axis=1).tolist()\n",
        "sample_size = min(50_000, len(texts))\n",
        "sample_texts = rng.choice(texts, size=sample_size, replace=False)\n",
        "\n",
        "lengths = np.array([token_len(t) for t in sample_texts], dtype=np.int32)\n",
        "\n",
        "p = [50, 75, 90, 95, 97, 98, 99, 99.5]\n",
        "qs = np.percentile(lengths, p)\n",
        "\n",
        "for perc, q in zip(p, qs):\n",
        "    print(f\"{perc:>5}%  -> {int(q)} tokens\")\n",
        "\n",
        "# Example choice:\n",
        "max_len = int(np.percentile(lengths, 95))\n",
        "print(\"Suggested max_len:\", max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "589d4101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589d4101",
        "outputId": "3b821899-83e6-4a9d-92e0-de391b49633a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n",
            "diff       diff --git a/lib/is_translatable.rb b/lib/is_t...\n",
            "message    Adding some failing specs to get the translati...\n",
            "Name: 0, dtype: object\n",
            "diff --git a/lib/is_translatable.rb b/lib/is_translatable.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/is_translatable.rb\n",
            "+++ b/lib/is_translatable.rb\n",
            "@@ -13,6 +13,9 @@ module IsTranslatable\n",
            " \n",
            "     def set_translation(kind, t, locale_override=nil)\n",
            "     end\n",
            "+\n",
            "+\tdef get_translation(kind, locale_override=nil)\n",
            "+\tend\n",
            "   end\n",
            " end\n",
            " \n",
            "diff --git a/spec/lib/is_translatable_spec.rb b/spec/lib/is_translatable_spec.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/spec/lib/is_translatable_spec.rb\n",
            "+++ b/spec/lib/is_translatable_spec.rb\n",
            "@@ -24,7 +24,20 @@ describe IsTranslatable do\n",
            "       context 'with translated title' do\n",
            "         before {@article.set_translation(:title, @titles[:es])}\n",
            "         it {should be_valid}\n",
            "-        it \"should check that it's actually translated\"\n",
            "+\n",
            "+        it {subject.get_translation(:title).should == @titles[:es]}\n",
            "+\n",
            "+\t\tcontext 'loaded from db' do\n",
            "+\t\t\tbefore :each do\n",
            "+\t\t\t\t@article.save!\n",
            "+\t\t\t\t@loaded_article = Article.find(@article.id)\n",
            "+\t\t\tend\n",
            "+\t\t\tsubject{@loaded_article}\n",
            "+\n",
            "+\t\t\tit {should be_valid}\n",
            "+\n",
            "+\t\t\tit {subject.get_translation(:title).should == @titles[:es]}\n",
            "+\t\tend\n",
            "       end\n",
            " \n",
            "       context 'with translated title and locale override' do\n",
            "Commit Message:\n",
            "Adding some failing specs to get the translation back.\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))\n",
        "def format_input(entry):\n",
        "\n",
        "    input_text = f\"{entry['diff']}\\nCommit Message:\\n{entry['message']}\"\n",
        "\n",
        "    return input_text\n",
        "print(train_df.iloc[0])\n",
        "print(format_input(train_df.iloc[0]))\n",
        "\n",
        "\n",
        "class CodeDiffMessageDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer,max_length=1024):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = 1024\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        self.encoded_text = None\n",
        "        entry = self.data.iloc[index]\n",
        "        code_diff_plus_message = format_input(entry)\n",
        "        self.encoded_text = tokenizer.encode(code_diff_plus_message,max_length=self.max_length,Truncation=True)\n",
        "        return self.encoded_text\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.data)/10)\n",
        "\n",
        "train_dataset = CodeDiffMessageDataset(train_df, tokenizer)\n",
        "\n",
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    device = None\n",
        "    if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "    else:\n",
        "      device = torch.device(\"cpu\")\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b407c551",
      "metadata": {
        "id": "b407c551"
      },
      "outputs": [],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_fn(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "92d84227",
      "metadata": {
        "id": "92d84227"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f607eca4",
      "metadata": {
        "id": "f607eca4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 4\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = CodeDiffMessageDataset(train_df, tokenizer)\n",
        "val_dataset = CodeDiffMessageDataset(val_df, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    shuffle= False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e2ad83a",
      "metadata": {
        "collapsed": true,
        "id": "9e2ad83a"
      },
      "outputs": [],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03a1b5ca",
      "metadata": {
        "collapsed": true,
        "id": "03a1b5ca"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(inputs[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015fb7b4",
      "metadata": {
        "collapsed": true,
        "id": "015fb7b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(targets[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dbef220d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbef220d",
        "outputId": "cede387b-30c9-48f6-a1eb-d8511c39dcdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50257\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.use_cache = False\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "print(tokenizer.vocab_size)\n",
        "model.config.pad_token_id\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "271512b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271512b0",
        "outputId": "0f68e404-32f6-48bb-88f8-096eef2cbeec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e5ed2cc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de90183fff1b4cf4a0862fe1c9fe62ef",
            "48b6e1877b2c49c9bc1b8b9fc51dd53b",
            "f262f30aef634b2cb490ed250f2fdde2",
            "057e8e4430d64f25b5294903d062369d",
            "f87e68a2b1be4ede9217ecf0ea2e2da9",
            "c14f83c26ab64ebfb0839a2ef10b663a",
            "6f61885f6b7d4a71b8804285cf9802ba",
            "93c9bb8fb04442cab7693302f6411458",
            "17cfad8f10384cfb85a81e2ef100f0ce",
            "256ec936d1ce4513b17cb09fa055d449",
            "5c284bbab3cd481d9168f18c72e92901",
            "84bcb37019bd43e789a8c5c3bbe8fa65",
            "e9fcef0e4faa4bbbad3fc33a4809b7ad",
            "db83a6358e34495d82cc4dc8ad2e188e",
            "be789e4225c54bbfb35916dc598fb6ea",
            "78961a27e14b41558ee813670c1a7780",
            "e30bcadf148a458e97b83fd48158a05d",
            "e6c97330b8424ba6ade65aee4920efed",
            "dce1237f66864694bbdd786286be4aba",
            "219f986690a6494faa7f03ab475cf437",
            "3b143e9f25c34c0587c8712e2a0feaaa",
            "9c537a0a6f6a4a6390d366511259f673"
          ]
        },
        "id": "e5ed2cc5",
        "outputId": "0b59f9bb-387b-4094-cc77-d5bb461dbbda"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1/2:   0%|          | 0/316 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de90183fff1b4cf4a0862fe1c9fe62ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "You may ignore this warning if your `pad_token_id` (50256) is identical to the `bos_token_id` (50256), `eos_token_id` (50256), or the `sep_token_id` (None), and your input is not padded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "Fixes #<I> issue.\n",
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "File: <URL>/files>\n",
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "Fix bug #<I>\n",
            "Summary Epoch 1: Train Loss: 1.7154 | Val Loss: 1.5253| PPL: 4.60\n",
            ">>> New best model saved!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 2/2:   0%|          | 0/316 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84bcb37019bd43e789a8c5c3bbe8fa65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "Fixes #<I>\n",
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "Fix #<I>\n",
            "\n",
            "[Generated]: Diff:\n",
            "--- a/file.py\n",
            "+++ b/file.py\n",
            "- print('hi')\n",
            "+ print('hello')\n",
            "\n",
            "Commit Message:\n",
            "Fix bug in Python <I>\n",
            "Summary Epoch 2: Train Loss: 1.3676 | Val Loss: 1.5076| PPL: 4.52\n",
            ">>> New best model saved!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "\n",
        "\n",
        "def calculate_accuracy(logits, labels):\n",
        "    predictions = torch.argmax(logits, dim=-1) #(batch_size, sequence_length, vocab_size)\n",
        "    correct_predictions = (predictions == labels).float() # (batch_size, sequence_length)\n",
        "    return correct_predictions.mean().item()\n",
        "\n",
        "def generate(model, tokenizer, device):\n",
        "    example_diff = \"--- a/file.py\\n+++ b/file.py\\n- print('hi')\\n+ print('hello')\"\n",
        "    prompt = f\"Diff:\\n{example_diff}\\n\\nCommit Message:\\n\"\n",
        "\n",
        "    inputs = tokenizer(\n",
        "        prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,\n",
        "        padding=True,\n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs[\"input_ids\"],\n",
        "            attention_mask=inputs[\"attention_mask\"],\n",
        "            max_new_tokens=50,\n",
        "            num_beams=5,\n",
        "            no_repeat_ngram_size=2,\n",
        "            early_stopping=True,\n",
        "            pad_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    print(f\"\\n[Generated]: {generated_text}\")\n",
        "\n",
        "# --- 2. Training Step ---\n",
        "def train_one_epoch(model, dataloader, optimizer, device, progress_bar, tokenizer):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x).logits\n",
        "        loss = nn.CrossEntropyLoss()(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            y.view(-1)\n",
        "        )\n",
        "        acc = calculate_accuracy(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc\n",
        "\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix({\"train_loss\": f\"{loss.item():.4f}\",\"acc\": f\"{acc:.4f}\"})\n",
        "\n",
        "\n",
        "        if i > 0 and i % 100 == 0:\n",
        "            generate(model, tokenizer, device)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_acc = total_acc / len(dataloader)\n",
        "    return avg_loss,avg_acc\n",
        "\n",
        "# --- 3. Evaluation Step ---\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x).logits\n",
        "            loss = nn.CrossEntropyLoss()(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                y.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "            total_acc  += calculate_accuracy(logits, y)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_acc = total_acc / len(dataloader)\n",
        "    return avg_loss,avg_acc\n",
        "\n",
        "\n",
        "# --- 4. Main Loop ---\n",
        "def train(model, train_loader, val_loader, optimizer, device, tokenizer):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience = 2\n",
        "    bad_epochs = 0\n",
        "    epochs = 2\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss,train_acc = train_one_epoch(model, train_loader, optimizer, device, progress_bar, tokenizer)\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss,val_acc = evaluate(model, val_loader, device)\n",
        "        try:\n",
        "            ppl = math.exp(val_loss)\n",
        "        except OverflowError:\n",
        "            ppl = float('inf')\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"train_loss\": f\"{train_loss:.4f}\",\n",
        "            \"train_accuracy\": f\"{train_acc:.4f}\",\n",
        "            \"val_loss\": f\"{val_loss:.4f}\",\n",
        "            \"val_accuracy\": f\"{val_acc:.4f}\",\n",
        "            \"PPL\": f\"{ppl:.2f}\"\n",
        "        })\n",
        "        progress_bar.refresh()\n",
        "        progress_bar.close() # Close bar to print new line\n",
        "\n",
        "        # Logging\n",
        "        print(f\"Summary Epoch {epoch+1}: Train Loss: {train_loss:.4f}| Train Accuracy: {train_acc:.4f} \\\n",
        "        | Val Loss: {val_loss:.4f}|Val Accuracy: {val_acc:.4f})| PPL: {ppl:.4f}\")\n",
        "\n",
        "        # Save checkpoints\n",
        "        torch.save(model.state_dict(), f\"{main_path}/gpt2_epoch{epoch+1}.pt\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            bad_epochs = 0\n",
        "            torch.save(model.state_dict(), f\"{main_path}/best_model.pt\")\n",
        "            print(\">>> New best model saved!\")\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            print(f\">>> No improvement (bad epochs: {bad_epochs})\")\n",
        "\n",
        "        if bad_epochs >= patience:\n",
        "            print(\"EARLY STOPPING TRIGGERED.\")\n",
        "            break\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "train(model, train_loader, val_loader, optimizer, device, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 1. Setup the App\n",
        "app = FastAPI(title=\"Git Diff to Commit Message API\")\n",
        "\n",
        "# 2. Define Request Schema\n",
        "# This ensures users send valid JSON with a \"diff\" field\n",
        "class DiffRequest(BaseModel):\n",
        "    diff: str\n",
        "    max_tokens: int = 50  # Default value, but user can change it\n",
        "\n",
        "# 3. Global Variables for Model (Loaded on Startup)\n",
        "model = None\n",
        "tokenizer = None\n",
        "device = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model, tokenizer, device\n",
        "\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"best_model.pt\" # Or your specific checkpoint path\n",
        "    BASE_MODEL_NAME = \"gpt2\"     # Needed for the tokenizer configuration\n",
        "\n",
        "    print(\"Loading model and tokenizer...\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load Tokenizer (Use the base gpt2 tokenizer)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Load Model Structure & Weights\n",
        "    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_NAME)\n",
        "    model.resize_token_embeddings(len(tokenizer)) # Important if you resized during training\n",
        "\n",
        "    # Load your fine-tuned weights\n",
        "    # map_location ensures it loads even if you move from GPU -> CPU\n",
        "    state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded successfully on {device}!\")\n",
        "\n",
        "# 4. Generation Endpoint\n",
        "@app.post(\"/generate\")\n",
        "async def generate_commit_message(request: DiffRequest):\n",
        "    if not model:\n",
        "        raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
        "\n",
        "    try:\n",
        "        # Format the input exactly how we trained it\n",
        "        prompt = f\"Diff:\\n{request.diff}\\n\\nCommit Message:\\n\"\n",
        "\n",
        "        # Tokenize\n",
        "        inputs = tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            max_length=512,\n",
        "            truncation=True,\n",
        "            padding=True\n",
        "        ).to(device)\n",
        "\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_new_tokens=request.max_tokens,\n",
        "                num_beams=5,\n",
        "                no_repeat_ngram_size=2,\n",
        "                early_stopping=True,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode\n",
        "        full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Post-processing: Extract only the commit message part\n",
        "        # We split by our known separator and take the last part\n",
        "        answer = full_text.split(\"Commit Message:\\n\")[-1].strip()\n",
        "\n",
        "        return {\n",
        "            \"generated_message\": answer,\n",
        "            \"full_text\": full_text\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# 5. Health Check\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"ok\", \"device\": str(device)}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuT6EsaEXBCT",
        "outputId": "5b95ad0c-3560-4c50-8606-07cff9b123fe"
      },
      "id": "DuT6EsaEXBCT",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-463976673.py:20: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "LPjyMHQ22xv8",
        "outputId": "ac59a620-7ed7-402c-a43d-ac3445e2fd51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "LPjyMHQ22xv8",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model.pt\t\t\t commitbench_validation.csv\n",
            "commitbench_test.csv\t\t GenerateApi.py\n",
            "commitbench_train_1pct.csv\t gpt2_epoch1.pt\n",
            "commitbench_train.csv\t\t gpt2_epoch2.pt\n",
            "commitbench_validation_1pct.csv  gpt2_first_training.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn GenerateApi:app --reload"
      ],
      "metadata": {
        "id": "0oOx0cx31Dqs",
        "outputId": "e23ce8d6-e64e-4b14-b51c-fcea7694738b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "0oOx0cx31Dqs",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content/drive/MyDrive/FinetuneLLM_Ergasia']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://127.0.0.1:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m21363\u001b[0m] using \u001b[36m\u001b[1mWatchFiles\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m21369\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "Loading model and tokenizer...\n",
            "2026-01-18 16:06:32.332422: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768752392.363738   21369 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768752392.374090   21369 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768752392.400656   21369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768752392.400692   21369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768752392.400700   21369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768752392.400707   21369 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Model loaded successfully on cuda!\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m21369\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m21363\u001b[0m]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://127.0.0.1:8000/generate\"\n",
        "data = {\"diff\": \"--- a/file.py\\n+++ b/file.py\\n- print('error')\\n+ print('fixed')\"}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json()['generated_message'])"
      ],
      "metadata": {
        "id": "eUFZzJlx3YxV",
        "outputId": "e8f102cb-5a0f-4ef5-813f-8ddcca9452b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eUFZzJlx3YxV",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fix(file) fix error handling\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bb60b268c3e43cda402c8025694f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59456630863f47d0a2e9a9501fe5e0c0",
              "IPY_MODEL_a653da5d099a4d2e9ab321a502696715",
              "IPY_MODEL_0e896eb89da1475d8550f90a03c36442"
            ],
            "layout": "IPY_MODEL_ed38f0951dd3497da6e36e294ec2c880"
          }
        },
        "59456630863f47d0a2e9a9501fe5e0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a19b53da804d4b8b8457c8ce17351e",
            "placeholder": "",
            "style": "IPY_MODEL_f55f84e0999740649d5f177be2bf06ea",
            "value": "README.md:"
          }
        },
        "a653da5d099a4d2e9ab321a502696715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60fe2c0871344828b004a0ca035f233",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33745e90c34c497b94fbd995fd47696e",
            "value": 1
          }
        },
        "0e896eb89da1475d8550f90a03c36442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc447e673bdc46de8f71f003cd30a914",
            "placeholder": "",
            "style": "IPY_MODEL_be28821e0f0241079aa0220411328584",
            "value": "5.67k/?[00:00&lt;00:00,341kB/s]"
          }
        },
        "ed38f0951dd3497da6e36e294ec2c880": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a19b53da804d4b8b8457c8ce17351e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55f84e0999740649d5f177be2bf06ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60fe2c0871344828b004a0ca035f233": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "33745e90c34c497b94fbd995fd47696e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bc447e673bdc46de8f71f003cd30a914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be28821e0f0241079aa0220411328584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cd40e349b734d60a5b760bf1232ba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30f6ac4276f547d0913b9b59ebe6bb69",
              "IPY_MODEL_3dc7f099bc69445fbd15e66731ca254c",
              "IPY_MODEL_5b21f33677794182a9d93ba8ebeb87cd"
            ],
            "layout": "IPY_MODEL_f5e05c7e75b9476688eaf110de279cc3"
          }
        },
        "30f6ac4276f547d0913b9b59ebe6bb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f78b24e1324ae199e4d294a9928a61",
            "placeholder": "",
            "style": "IPY_MODEL_aa08721eaf914e628c9a9c3889ae8ae5",
            "value": "train.csv:0%"
          }
        },
        "3dc7f099bc69445fbd15e66731ca254c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf46190f9d2542789096244ff9f159c4",
            "max": 1051789145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15ba200bada44afebfce411f0a08aa51",
            "value": 0
          }
        },
        "5b21f33677794182a9d93ba8ebeb87cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de406d179c134a649395ac4b5c5e9f07",
            "placeholder": "",
            "style": "IPY_MODEL_c57e18d56dde4a28a7f54e9bf8a44c6b",
            "value": "0.00/1.05G[00:00&lt;?,?B/s]"
          }
        },
        "f5e05c7e75b9476688eaf110de279cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76f78b24e1324ae199e4d294a9928a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa08721eaf914e628c9a9c3889ae8ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf46190f9d2542789096244ff9f159c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15ba200bada44afebfce411f0a08aa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "de406d179c134a649395ac4b5c5e9f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57e18d56dde4a28a7f54e9bf8a44c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de90183fff1b4cf4a0862fe1c9fe62ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48b6e1877b2c49c9bc1b8b9fc51dd53b",
              "IPY_MODEL_f262f30aef634b2cb490ed250f2fdde2",
              "IPY_MODEL_057e8e4430d64f25b5294903d062369d"
            ],
            "layout": "IPY_MODEL_f87e68a2b1be4ede9217ecf0ea2e2da9"
          }
        },
        "48b6e1877b2c49c9bc1b8b9fc51dd53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14f83c26ab64ebfb0839a2ef10b663a",
            "placeholder": "",
            "style": "IPY_MODEL_6f61885f6b7d4a71b8804285cf9802ba",
            "value": "Epoch1/2:100%"
          }
        },
        "f262f30aef634b2cb490ed250f2fdde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c9bb8fb04442cab7693302f6411458",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17cfad8f10384cfb85a81e2ef100f0ce",
            "value": 316
          }
        },
        "057e8e4430d64f25b5294903d062369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256ec936d1ce4513b17cb09fa055d449",
            "placeholder": "",
            "style": "IPY_MODEL_5c284bbab3cd481d9168f18c72e92901",
            "value": "316/316[03:32&lt;00:00,1.48it/s,train_loss=1.7154,train_accuracy=0.4933,val_loss=1.5253,val_accuracy=0.5135,PPL=4.60]"
          }
        },
        "f87e68a2b1be4ede9217ecf0ea2e2da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c14f83c26ab64ebfb0839a2ef10b663a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f61885f6b7d4a71b8804285cf9802ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c9bb8fb04442cab7693302f6411458": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17cfad8f10384cfb85a81e2ef100f0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "256ec936d1ce4513b17cb09fa055d449": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c284bbab3cd481d9168f18c72e92901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84bcb37019bd43e789a8c5c3bbe8fa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9fcef0e4faa4bbbad3fc33a4809b7ad",
              "IPY_MODEL_db83a6358e34495d82cc4dc8ad2e188e",
              "IPY_MODEL_be789e4225c54bbfb35916dc598fb6ea"
            ],
            "layout": "IPY_MODEL_78961a27e14b41558ee813670c1a7780"
          }
        },
        "e9fcef0e4faa4bbbad3fc33a4809b7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30bcadf148a458e97b83fd48158a05d",
            "placeholder": "",
            "style": "IPY_MODEL_e6c97330b8424ba6ade65aee4920efed",
            "value": "Epoch2/2:100%"
          }
        },
        "db83a6358e34495d82cc4dc8ad2e188e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce1237f66864694bbdd786286be4aba",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_219f986690a6494faa7f03ab475cf437",
            "value": 316
          }
        },
        "be789e4225c54bbfb35916dc598fb6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b143e9f25c34c0587c8712e2a0feaaa",
            "placeholder": "",
            "style": "IPY_MODEL_9c537a0a6f6a4a6390d366511259f673",
            "value": "316/316[03:28&lt;00:00,1.71it/s,train_loss=1.3676,train_accuracy=0.5268,val_loss=1.5076,val_accuracy=0.5144,PPL=4.52]"
          }
        },
        "78961a27e14b41558ee813670c1a7780": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30bcadf148a458e97b83fd48158a05d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c97330b8424ba6ade65aee4920efed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dce1237f66864694bbdd786286be4aba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219f986690a6494faa7f03ab475cf437": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b143e9f25c34c0587c8712e2a0feaaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c537a0a6f6a4a6390d366511259f673": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}