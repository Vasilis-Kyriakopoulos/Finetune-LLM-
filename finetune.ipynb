{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasilis-Kyriakopoulos/Finetune-LLM-/blob/main/finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61cd394d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "2bb60b268c3e43cda402c8025694f047",
            "59456630863f47d0a2e9a9501fe5e0c0",
            "a653da5d099a4d2e9ab321a502696715",
            "0e896eb89da1475d8550f90a03c36442",
            "ed38f0951dd3497da6e36e294ec2c880",
            "f0a19b53da804d4b8b8457c8ce17351e",
            "f55f84e0999740649d5f177be2bf06ea",
            "d60fe2c0871344828b004a0ca035f233",
            "33745e90c34c497b94fbd995fd47696e",
            "bc447e673bdc46de8f71f003cd30a914",
            "be28821e0f0241079aa0220411328584",
            "1cd40e349b734d60a5b760bf1232ba08",
            "30f6ac4276f547d0913b9b59ebe6bb69",
            "3dc7f099bc69445fbd15e66731ca254c",
            "5b21f33677794182a9d93ba8ebeb87cd",
            "f5e05c7e75b9476688eaf110de279cc3",
            "76f78b24e1324ae199e4d294a9928a61",
            "aa08721eaf914e628c9a9c3889ae8ae5",
            "cf46190f9d2542789096244ff9f159c4",
            "15ba200bada44afebfce411f0a08aa51",
            "de406d179c134a649395ac4b5c5e9f07",
            "c57e18d56dde4a28a7f54e9bf8a44c6b"
          ]
        },
        "id": "61cd394d",
        "outputId": "985f29ca-56df-465b-ec6d-b35f5353da74"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# ds = load_dataset(\"maxscha/commitbench\")\n",
        "# main_path = \"data/\"\n",
        "\n",
        "# cols = [\"diff\", \"message\"]\n",
        "\n",
        "\n",
        "# ds[\"train\"].select_columns(cols) \\\n",
        "#     .to_pandas() \\\n",
        "#     .to_csv(main_path+\"commitbench_train.csv\", index=False)\n",
        "\n",
        "\n",
        "# ds[\"validation\"].select_columns(cols) \\\n",
        "#     .to_pandas() \\\n",
        "#     .to_csv(main_path+\"commitbench_validation.csv\",index=False)\n",
        "\n",
        "\n",
        "# ds[\"test\"].select_columns(cols) \\\n",
        "#     .to_pandas() \\\n",
        "#     .to_csv(main_path+\"commitbench_test.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "gTR0NtL4Lfd8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTR0NtL4Lfd8",
        "outputId": "bfa7f987-f3ac-4d78-aed8-b98cfd80934f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length Train:1165213\n",
            "Length Val:249689\n",
            "New Length Train: 922727\n",
            "New Length Val: 197931\n"
          ]
        }
      ],
      "source": [
        "#from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "main_path = \"data/\"\n",
        "train_df = pd.read_csv(main_path + \"commitbench_train.csv\")\n",
        "val_df = pd.read_csv(main_path + \"commitbench_validation.csv\")\n",
        "print(f\"Length Train:{len(train_df)}\")\n",
        "print(f\"Length Val:{len(val_df)}\")\n",
        "\n",
        "train_df = train_df[train_df[\"diff\"].str.len() < 1000].reset_index(drop=True)\n",
        "val_df = val_df[val_df[\"diff\"].str.len() < 1000].reset_index(drop=True)\n",
        "train_df = train_df[~train_df['message'].str.contains('^Fixes #', na=False)]\n",
        "\n",
        "print(f\"New Length Train: {len(train_df)}\")\n",
        "print(f\"New Length Val: {len(val_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b70bb305",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "b70bb305",
        "outputId": "cca40dc9-3682-4465-f86f-6d7594e10948"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# input_csv = main_path + \"commitbench_validation.csv\"\n",
        "# output_csv = main_path + \"commitbench_validation_10pct.csv\"\n",
        "\n",
        "# chunk_size = 100_000\n",
        "# keep_frac = 0.1\n",
        "# first = True\n",
        "\n",
        "# for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
        "#     sampled = chunk.sample(frac=keep_frac, random_state=42)\n",
        "\n",
        "#     sampled.to_csv(\n",
        "#         output_csv,\n",
        "#         mode=\"a\",\n",
        "#         index=False,\n",
        "#         header=first\n",
        "#     )\n",
        "#     first = False\n",
        "\n",
        "\n",
        "# input_csv = main_path + \"commitbench_train.csv\"\n",
        "# output_csv = main_path + \"commitbench_train_10pct.csv\"\n",
        "\n",
        "# chunk_size = 100_000\n",
        "# keep_frac = 0.1\n",
        "# first = True\n",
        "\n",
        "# for chunk in pd.read_csv(input_csv, chunksize=chunk_size):\n",
        "#     sampled = chunk.sample(frac=keep_frac, random_state=42)\n",
        "\n",
        "#     sampled.to_csv(\n",
        "#         output_csv,\n",
        "#         mode=\"a\",\n",
        "#         index=False,\n",
        "#         header=first\n",
        "#     )\n",
        "#     first = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "DHsGmVCtOuXn",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "DHsGmVCtOuXn",
        "outputId": "a9ae21cc-b962-42cc-f725-993edcaf1499"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>diff --git a/lib/bibreformat.py b/lib/bibrefor...</td>\n",
              "      <td>BibFormat: HDREF processing bug fix\\n\\n* Fixes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diff --git a/src/lib/Supra/Controller/Pages/Tw...</td>\n",
              "      <td>Task #&lt;I&gt;: Block titles\\nfast-fix implementati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>diff --git a/test/unit/serializers/cbor.spec.j...</td>\n",
              "      <td>Add additional cbor test for useTag&lt;I&gt;ForMaps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diff --git a/setup.py b/setup.py\\nindex &lt;HASH&gt;...</td>\n",
              "      <td>[build] Add tests' requires in setup.py</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diff --git a/lib/macho/load_commands.rb b/lib/...</td>\n",
              "      <td>map lazy/upward dylib to proper load command\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                diff  \\\n",
              "0  diff --git a/lib/bibreformat.py b/lib/bibrefor...   \n",
              "1  diff --git a/src/lib/Supra/Controller/Pages/Tw...   \n",
              "2  diff --git a/test/unit/serializers/cbor.spec.j...   \n",
              "3  diff --git a/setup.py b/setup.py\\nindex <HASH>...   \n",
              "4  diff --git a/lib/macho/load_commands.rb b/lib/...   \n",
              "\n",
              "                                             message  \n",
              "0  BibFormat: HDREF processing bug fix\\n\\n* Fixes...  \n",
              "1  Task #<I>: Block titles\\nfast-fix implementati...  \n",
              "2      Add additional cbor test for useTag<I>ForMaps  \n",
              "3            [build] Add tests' requires in setup.py  \n",
              "4  map lazy/upward dylib to proper load command\\n...  "
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "hMdTmrknPg1m",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "hMdTmrknPg1m",
        "outputId": "e7ddae5a-eebe-4101-e3e0-116ee5fb3a3e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>diff --git a/redisson/src/main/java/org/rediss...</td>\n",
              "      <td>Fixed - Redisson cluster cannot recover if Red...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diff --git a/translate/coroutines.py b/transla...</td>\n",
              "      <td>bug fix when transliteration doesnt exist prin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>diff --git a/setup.py b/setup.py\\nindex &lt;HASH&gt;...</td>\n",
              "      <td>add feature_selection to setup.py</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diff --git a/src/resources/views/admin/_index....</td>\n",
              "      <td>.btn outside of title h1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diff --git a/Db.php b/Db.php\\nindex &lt;HASH&gt;..&lt;H...</td>\n",
              "      <td>Accept empty condition in smartSelect</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                diff  \\\n",
              "0  diff --git a/redisson/src/main/java/org/rediss...   \n",
              "1  diff --git a/translate/coroutines.py b/transla...   \n",
              "2  diff --git a/setup.py b/setup.py\\nindex <HASH>...   \n",
              "3  diff --git a/src/resources/views/admin/_index....   \n",
              "4  diff --git a/Db.php b/Db.php\\nindex <HASH>..<H...   \n",
              "\n",
              "                                             message  \n",
              "0  Fixed - Redisson cluster cannot recover if Red...  \n",
              "1  bug fix when transliteration doesnt exist prin...  \n",
              "2                  add feature_selection to setup.py  \n",
              "3                           .btn outside of title h1  \n",
              "4              Accept empty condition in smartSelect  "
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "val_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "c66a30e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "c66a30e5",
        "outputId": "f55b420d-2e26-459f-edb3-7abf0c0f48ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   50%  -> 293 tokens\n",
            "   75%  -> 363 tokens\n",
            "   90%  -> 423 tokens\n",
            "   95%  -> 458 tokens\n",
            "   97%  -> 479 tokens\n",
            "   98%  -> 496 tokens\n",
            "   99%  -> 524 tokens\n",
            " 99.5%  -> 550 tokens\n",
            "Suggested max_len: 458\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def format_input(entry):\n",
        "\n",
        "    input_text = f\"{entry['diff']}\\nCommit Message:\\n{entry['message']}\"\n",
        "\n",
        "    return input_text\n",
        "\n",
        "def token_len(t: str) -> int:\n",
        "    return len(tokenizer.encode(t, add_special_tokens=True))\n",
        "\n",
        "\n",
        "rng = np.random.default_rng(42)\n",
        "texts = train_df.apply(format_input, axis=1).tolist()\n",
        "sample_size = min(50_000, len(texts))\n",
        "sample_texts = rng.choice(texts, size=sample_size, replace=False)\n",
        "\n",
        "lengths = np.array([token_len(t) for t in sample_texts], dtype=np.int32)\n",
        "\n",
        "p = [50, 75, 90, 95, 97, 98, 99, 99.5]\n",
        "qs = np.percentile(lengths, p)\n",
        "\n",
        "for perc, q in zip(p, qs):\n",
        "    print(f\"{perc:>5}%  -> {int(q)} tokens\")\n",
        "\n",
        "# Example choice:\n",
        "max_len = int(np.percentile(lengths, 95))\n",
        "print(\"Suggested max_len:\", max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "589d4101",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "589d4101",
        "outputId": "3b821899-83e6-4a9d-92e0-de391b49633a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50256]\n",
            "diff       diff --git a/lib/bibreformat.py b/lib/bibrefor...\n",
            "message    BibFormat: HDREF processing bug fix\\n\\n* Fixes...\n",
            "Name: 0, dtype: object\n",
            "diff --git a/lib/bibreformat.py b/lib/bibreformat.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/bibreformat.py\n",
            "+++ b/lib/bibreformat.py\n",
            "@@ -126,7 +126,7 @@ def bibreformat_task(fmt, sql, sql_queries, cds_query, process_format, process, \n",
            "         write_message(\"Querying database (%s) ...\" % sql_query, verbose=2)\n",
            "         recIDs |= intbitset(run_sql(sql_query))\n",
            " \n",
            "-    if fmt == \"HDREF\":\n",
            "+    if fmt == \"HDREF\" and recIDs:\n",
            "         # HDREF represents the references tab\n",
            "         # the tab needs to be recomputed not only when the record changes\n",
            "         # but also when one of the citations changes\n",
            "Commit Message:\n",
            "BibFormat: HDREF processing bug fix\n",
            "\n",
            "* Fixes bug that would occur with empty records when processing HDREF.\n",
            "  (closes #<I>)\n",
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import re\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\"))\n",
        "print(train_df.iloc[0])\n",
        "print(format_input(train_df.iloc[0]))\n",
        "\n",
        "def clean_text(text):\n",
        "    # 1. Remove SHA-1 hashes (usually 7-40 hex characters)\n",
        "    text = re.sub(r'\\b[0-9a-f]{7,40}\\b', '', text)\n",
        "    \n",
        "    # 2. Remove Git metadata like \"Signed-off-by\" or \"Co-authored-by\"\n",
        "    text = re.sub(r'^(Signed-off-by|Co-authored-by|Reported-by):.*$', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # 3. Remove excessive newlines and whitespace\n",
        "    text = re.sub(r'\\n\\s*\\n', '\\n', text)\n",
        "\n",
        "    # 1. Αφαίρεση της γραμμής 'index <hash>..<hash> <mode>'\n",
        "    text = re.sub(r'^index [0-9a-fA-F]+\\.\\.[0-9a-fA-F]+ \\d+\\n', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # 2. Απλοποίηση του 'diff --git a/path/to/file b/path/to/file' \n",
        "    # σε 'FILE: path/to/file' για εξοικονόμηση tokens\n",
        "    text = re.sub(r'^diff --git a/(.*) b/(.*)\\n', r'FILE: \\1\\n', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # 3. Αφαίρεση των γραμμών --- a/ και +++ b/ (είναι πλεονασμός αφού έχουμε το FILE:)\n",
        "    text = re.sub(r'^--- a/.*\\n', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'^\\+\\+\\+ b/.*\\n', '', text, flags=re.MULTILINE)\n",
        "    return text.strip()\n",
        "\n",
        "\n",
        "class CodeDiffMessageDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer,max_length=512):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = 512\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        entry = self.data.iloc[index]\n",
        "        \n",
        "        # Clean the components\n",
        "        clean_diff = clean_text(entry['diff'])\n",
        "        clean_msg = clean_text(entry['message'])\n",
        "\n",
        "        # Structure: <|endoftext|> DIFF: ... MESSAGE: ... <|endoftext|>\n",
        "        prompt = f\"<|endoftext|>DIFF:\\n{clean_diff}\\n\\nCOMMIT MESSAGE:\\n\"\n",
        "        full_text = f\"{prompt}{clean_msg}<|endoftext|>\"\n",
        "\n",
        "        encoded_full = self.tokenizer.encode(full_text, max_length=self.max_length, truncation=True)\n",
        "        encoded_prompt = self.tokenizer.encode(prompt, max_length=self.max_length, truncation=True)\n",
        "        \n",
        "        return  encoded_full\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(len(self.data)/10)\n",
        "\n",
        "train_dataset = CodeDiffMessageDataset(train_df, tokenizer)\n",
        "\n",
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "):\n",
        "    # Find the longest sequence in the batch\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # Pad and prepare inputs and targets\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # Add an <|endoftext|> token\n",
        "        new_item += [pad_token_id]\n",
        "        # Pad sequences to max_length\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # Truncate the last token for inputs\n",
        "        targets = torch.tensor(padded[1:])  # Shift +1 to the right for targets\n",
        "\n",
        "        # New: Replace all but the first padding tokens in targets by ignore_index\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # Convert list of inputs and targets to tensors and transfer to target device\n",
        "    device = None\n",
        "    if torch.cuda.is_available():\n",
        "      device = torch.device(\"cuda\")\n",
        "    else:\n",
        "      device = torch.device(\"cpu\")\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b407c551",
      "metadata": {
        "id": "b407c551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]], device='cuda:0'), tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]], device='cuda:0'))\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_fn(batch))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "f607eca4",
      "metadata": {
        "id": "f607eca4"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 4\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = CodeDiffMessageDataset(train_df, tokenizer)\n",
        "val_dataset = CodeDiffMessageDataset(val_df, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=custom_collate_fn,\n",
        "    shuffle= False,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "9e2ad83a",
      "metadata": {
        "collapsed": true,
        "id": "9e2ad83a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loader:\n",
            "torch.Size([4, 490]) torch.Size([4, 490])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 273]) torch.Size([4, 273])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 255]) torch.Size([4, 255])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 311]) torch.Size([4, 311])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 494]) torch.Size([4, 494])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 255]) torch.Size([4, 255])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 242]) torch.Size([4, 242])\n",
            "torch.Size([4, 329]) torch.Size([4, 329])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 296]) torch.Size([4, 296])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 292]) torch.Size([4, 292])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 505]) torch.Size([4, 505])\n",
            "torch.Size([4, 494]) torch.Size([4, 494])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 293]) torch.Size([4, 293])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 277]) torch.Size([4, 277])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 296]) torch.Size([4, 296])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 312]) torch.Size([4, 312])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 480]) torch.Size([4, 480])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 290]) torch.Size([4, 290])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 376]) torch.Size([4, 376])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 299]) torch.Size([4, 299])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 312]) torch.Size([4, 312])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 280]) torch.Size([4, 280])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 262]) torch.Size([4, 262])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 291]) torch.Size([4, 291])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 265]) torch.Size([4, 265])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 348]) torch.Size([4, 348])\n",
            "torch.Size([4, 322]) torch.Size([4, 322])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 283]) torch.Size([4, 283])\n",
            "torch.Size([4, 485]) torch.Size([4, 485])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 293]) torch.Size([4, 293])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 287]) torch.Size([4, 287])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 502]) torch.Size([4, 502])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 501]) torch.Size([4, 501])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 276]) torch.Size([4, 276])\n",
            "torch.Size([4, 257]) torch.Size([4, 257])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 483]) torch.Size([4, 483])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 474]) torch.Size([4, 474])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 325]) torch.Size([4, 325])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 482]) torch.Size([4, 482])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 264]) torch.Size([4, 264])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 270]) torch.Size([4, 270])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 290]) torch.Size([4, 290])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 299]) torch.Size([4, 299])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 472]) torch.Size([4, 472])\n",
            "torch.Size([4, 493]) torch.Size([4, 493])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 510]) torch.Size([4, 510])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 344]) torch.Size([4, 344])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 313]) torch.Size([4, 313])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 295]) torch.Size([4, 295])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 273]) torch.Size([4, 273])\n",
            "torch.Size([4, 474]) torch.Size([4, 474])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 292]) torch.Size([4, 292])\n",
            "torch.Size([4, 502]) torch.Size([4, 502])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 256]) torch.Size([4, 256])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 490]) torch.Size([4, 490])\n",
            "torch.Size([4, 486]) torch.Size([4, 486])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 258]) torch.Size([4, 258])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 286]) torch.Size([4, 286])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 238]) torch.Size([4, 238])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 279]) torch.Size([4, 279])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 304]) torch.Size([4, 304])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 294]) torch.Size([4, 294])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 241]) torch.Size([4, 241])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 505]) torch.Size([4, 505])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 497]) torch.Size([4, 497])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 473]) torch.Size([4, 473])\n",
            "torch.Size([4, 284]) torch.Size([4, 284])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 281]) torch.Size([4, 281])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 376]) torch.Size([4, 376])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 501]) torch.Size([4, 501])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 258]) torch.Size([4, 258])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 304]) torch.Size([4, 304])\n",
            "torch.Size([4, 504]) torch.Size([4, 504])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 474]) torch.Size([4, 474])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 272]) torch.Size([4, 272])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 494]) torch.Size([4, 494])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 265]) torch.Size([4, 265])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 252]) torch.Size([4, 252])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 335]) torch.Size([4, 335])\n",
            "torch.Size([4, 262]) torch.Size([4, 262])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 510]) torch.Size([4, 510])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 509]) torch.Size([4, 509])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 376]) torch.Size([4, 376])\n",
            "torch.Size([4, 233]) torch.Size([4, 233])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 376]) torch.Size([4, 376])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 258]) torch.Size([4, 258])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 507]) torch.Size([4, 507])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 322]) torch.Size([4, 322])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 288]) torch.Size([4, 288])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 472]) torch.Size([4, 472])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 348]) torch.Size([4, 348])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 325]) torch.Size([4, 325])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 335]) torch.Size([4, 335])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 284]) torch.Size([4, 284])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 503]) torch.Size([4, 503])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 481]) torch.Size([4, 481])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 493]) torch.Size([4, 493])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 312]) torch.Size([4, 312])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 286]) torch.Size([4, 286])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 484]) torch.Size([4, 484])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 502]) torch.Size([4, 502])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 276]) torch.Size([4, 276])\n",
            "torch.Size([4, 483]) torch.Size([4, 483])\n",
            "torch.Size([4, 266]) torch.Size([4, 266])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 300]) torch.Size([4, 300])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 473]) torch.Size([4, 473])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 269]) torch.Size([4, 269])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 247]) torch.Size([4, 247])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 288]) torch.Size([4, 288])\n",
            "torch.Size([4, 493]) torch.Size([4, 493])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 329]) torch.Size([4, 329])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 492]) torch.Size([4, 492])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 278]) torch.Size([4, 278])\n",
            "torch.Size([4, 265]) torch.Size([4, 265])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 323]) torch.Size([4, 323])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 323]) torch.Size([4, 323])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 492]) torch.Size([4, 492])\n",
            "torch.Size([4, 274]) torch.Size([4, 274])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 311]) torch.Size([4, 311])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 303]) torch.Size([4, 303])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 473]) torch.Size([4, 473])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 493]) torch.Size([4, 493])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 462]) torch.Size([4, 462])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 281]) torch.Size([4, 281])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 261]) torch.Size([4, 261])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 510]) torch.Size([4, 510])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 510]) torch.Size([4, 510])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 322]) torch.Size([4, 322])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 503]) torch.Size([4, 503])\n",
            "torch.Size([4, 483]) torch.Size([4, 483])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 304]) torch.Size([4, 304])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 305]) torch.Size([4, 305])\n",
            "torch.Size([4, 280]) torch.Size([4, 280])\n",
            "torch.Size([4, 501]) torch.Size([4, 501])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 293]) torch.Size([4, 293])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 490]) torch.Size([4, 490])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 303]) torch.Size([4, 303])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 253]) torch.Size([4, 253])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 277]) torch.Size([4, 277])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 251]) torch.Size([4, 251])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 286]) torch.Size([4, 286])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 286]) torch.Size([4, 286])\n",
            "torch.Size([4, 259]) torch.Size([4, 259])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 497]) torch.Size([4, 497])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 348]) torch.Size([4, 348])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 274]) torch.Size([4, 274])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 253]) torch.Size([4, 253])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 344]) torch.Size([4, 344])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 317]) torch.Size([4, 317])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 325]) torch.Size([4, 325])\n",
            "torch.Size([4, 271]) torch.Size([4, 271])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 317]) torch.Size([4, 317])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 268]) torch.Size([4, 268])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 305]) torch.Size([4, 305])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 511]) torch.Size([4, 511])\n",
            "torch.Size([4, 262]) torch.Size([4, 262])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 272]) torch.Size([4, 272])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 480]) torch.Size([4, 480])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 292]) torch.Size([4, 292])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 486]) torch.Size([4, 486])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 282]) torch.Size([4, 282])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 247]) torch.Size([4, 247])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 294]) torch.Size([4, 294])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 485]) torch.Size([4, 485])\n",
            "torch.Size([4, 320]) torch.Size([4, 320])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 311]) torch.Size([4, 311])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 344]) torch.Size([4, 344])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 335]) torch.Size([4, 335])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 240]) torch.Size([4, 240])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 278]) torch.Size([4, 278])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 492]) torch.Size([4, 492])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 274]) torch.Size([4, 274])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 301]) torch.Size([4, 301])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 317]) torch.Size([4, 317])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 312]) torch.Size([4, 312])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 252]) torch.Size([4, 252])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 294]) torch.Size([4, 294])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 285]) torch.Size([4, 285])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 299]) torch.Size([4, 299])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 485]) torch.Size([4, 485])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 299]) torch.Size([4, 299])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 483]) torch.Size([4, 483])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 279]) torch.Size([4, 279])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 231]) torch.Size([4, 231])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 282]) torch.Size([4, 282])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 275]) torch.Size([4, 275])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 497]) torch.Size([4, 497])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 335]) torch.Size([4, 335])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 313]) torch.Size([4, 313])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 320]) torch.Size([4, 320])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 485]) torch.Size([4, 485])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 502]) torch.Size([4, 502])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 481]) torch.Size([4, 481])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 260]) torch.Size([4, 260])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 507]) torch.Size([4, 507])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 290]) torch.Size([4, 290])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 462]) torch.Size([4, 462])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 443]) torch.Size([4, 443])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 344]) torch.Size([4, 344])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 291]) torch.Size([4, 291])\n",
            "torch.Size([4, 269]) torch.Size([4, 269])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 490]) torch.Size([4, 490])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 305]) torch.Size([4, 305])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 282]) torch.Size([4, 282])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 500]) torch.Size([4, 500])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 482]) torch.Size([4, 482])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 284]) torch.Size([4, 284])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 280]) torch.Size([4, 280])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 263]) torch.Size([4, 263])\n",
            "torch.Size([4, 480]) torch.Size([4, 480])\n",
            "torch.Size([4, 487]) torch.Size([4, 487])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 323]) torch.Size([4, 323])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 450]) torch.Size([4, 450])\n",
            "torch.Size([4, 255]) torch.Size([4, 255])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 293]) torch.Size([4, 293])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 463]) torch.Size([4, 463])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 313]) torch.Size([4, 313])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 320]) torch.Size([4, 320])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 351]) torch.Size([4, 351])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 484]) torch.Size([4, 484])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 286]) torch.Size([4, 286])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 312]) torch.Size([4, 312])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 261]) torch.Size([4, 261])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 416]) torch.Size([4, 416])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 483]) torch.Size([4, 483])\n",
            "torch.Size([4, 494]) torch.Size([4, 494])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 498]) torch.Size([4, 498])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 313]) torch.Size([4, 313])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 324]) torch.Size([4, 324])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 305]) torch.Size([4, 305])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 376]) torch.Size([4, 376])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 329]) torch.Size([4, 329])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 498]) torch.Size([4, 498])\n",
            "torch.Size([4, 502]) torch.Size([4, 502])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 482]) torch.Size([4, 482])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 310]) torch.Size([4, 310])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 295]) torch.Size([4, 295])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 280]) torch.Size([4, 280])\n",
            "torch.Size([4, 481]) torch.Size([4, 481])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 503]) torch.Size([4, 503])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 348]) torch.Size([4, 348])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 278]) torch.Size([4, 278])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 284]) torch.Size([4, 284])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 307]) torch.Size([4, 307])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 300]) torch.Size([4, 300])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 508]) torch.Size([4, 508])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 507]) torch.Size([4, 507])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 473]) torch.Size([4, 473])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 222]) torch.Size([4, 222])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 287]) torch.Size([4, 287])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 399]) torch.Size([4, 399])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 328]) torch.Size([4, 328])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 486]) torch.Size([4, 486])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 272]) torch.Size([4, 272])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 441]) torch.Size([4, 441])\n",
            "torch.Size([4, 330]) torch.Size([4, 330])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 254]) torch.Size([4, 254])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 319]) torch.Size([4, 319])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 356]) torch.Size([4, 356])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 344]) torch.Size([4, 344])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 264]) torch.Size([4, 264])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 481]) torch.Size([4, 481])\n",
            "torch.Size([4, 392]) torch.Size([4, 392])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 304]) torch.Size([4, 304])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 317]) torch.Size([4, 317])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 323]) torch.Size([4, 323])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 322]) torch.Size([4, 322])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 267]) torch.Size([4, 267])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 498]) torch.Size([4, 498])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 267]) torch.Size([4, 267])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 331]) torch.Size([4, 331])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 266]) torch.Size([4, 266])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 507]) torch.Size([4, 507])\n",
            "torch.Size([4, 439]) torch.Size([4, 439])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 480]) torch.Size([4, 480])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 510]) torch.Size([4, 510])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 303]) torch.Size([4, 303])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 457]) torch.Size([4, 457])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 417]) torch.Size([4, 417])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 273]) torch.Size([4, 273])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 282]) torch.Size([4, 282])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 427]) torch.Size([4, 427])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 377]) torch.Size([4, 377])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 474]) torch.Size([4, 474])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 256]) torch.Size([4, 256])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 476]) torch.Size([4, 476])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 287]) torch.Size([4, 287])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 320]) torch.Size([4, 320])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 329]) torch.Size([4, 329])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 318]) torch.Size([4, 318])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 256]) torch.Size([4, 256])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 372]) torch.Size([4, 372])\n",
            "torch.Size([4, 501]) torch.Size([4, 501])\n",
            "torch.Size([4, 316]) torch.Size([4, 316])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 375]) torch.Size([4, 375])\n",
            "torch.Size([4, 335]) torch.Size([4, 335])\n",
            "torch.Size([4, 363]) torch.Size([4, 363])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 482]) torch.Size([4, 482])\n",
            "torch.Size([4, 348]) torch.Size([4, 348])\n",
            "torch.Size([4, 297]) torch.Size([4, 297])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 421]) torch.Size([4, 421])\n",
            "torch.Size([4, 434]) torch.Size([4, 434])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 290]) torch.Size([4, 290])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 362]) torch.Size([4, 362])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 323]) torch.Size([4, 323])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 423]) torch.Size([4, 423])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 468]) torch.Size([4, 468])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 480]) torch.Size([4, 480])\n",
            "torch.Size([4, 315]) torch.Size([4, 315])\n",
            "torch.Size([4, 436]) torch.Size([4, 436])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 309]) torch.Size([4, 309])\n",
            "torch.Size([4, 366]) torch.Size([4, 366])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 327]) torch.Size([4, 327])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 455]) torch.Size([4, 455])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 341]) torch.Size([4, 341])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 469]) torch.Size([4, 469])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 263]) torch.Size([4, 263])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 263]) torch.Size([4, 263])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 252]) torch.Size([4, 252])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 467]) torch.Size([4, 467])\n",
            "torch.Size([4, 488]) torch.Size([4, 488])\n",
            "torch.Size([4, 456]) torch.Size([4, 456])\n",
            "torch.Size([4, 482]) torch.Size([4, 482])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 244]) torch.Size([4, 244])\n",
            "torch.Size([4, 290]) torch.Size([4, 290])\n",
            "torch.Size([4, 326]) torch.Size([4, 326])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 269]) torch.Size([4, 269])\n",
            "torch.Size([4, 462]) torch.Size([4, 462])\n",
            "torch.Size([4, 471]) torch.Size([4, 471])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 338]) torch.Size([4, 338])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 405]) torch.Size([4, 405])\n",
            "torch.Size([4, 498]) torch.Size([4, 498])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 269]) torch.Size([4, 269])\n",
            "torch.Size([4, 470]) torch.Size([4, 470])\n",
            "torch.Size([4, 465]) torch.Size([4, 465])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 428]) torch.Size([4, 428])\n",
            "torch.Size([4, 481]) torch.Size([4, 481])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 345]) torch.Size([4, 345])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 308]) torch.Size([4, 308])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 454]) torch.Size([4, 454])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 484]) torch.Size([4, 484])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 448]) torch.Size([4, 448])\n",
            "torch.Size([4, 387]) torch.Size([4, 387])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 347]) torch.Size([4, 347])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 404]) torch.Size([4, 404])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 296]) torch.Size([4, 296])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 314]) torch.Size([4, 314])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 389]) torch.Size([4, 389])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 406]) torch.Size([4, 406])\n",
            "torch.Size([4, 358]) torch.Size([4, 358])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 432]) torch.Size([4, 432])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 282]) torch.Size([4, 282])\n",
            "torch.Size([4, 464]) torch.Size([4, 464])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 380]) torch.Size([4, 380])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 291]) torch.Size([4, 291])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 306]) torch.Size([4, 306])\n",
            "torch.Size([4, 447]) torch.Size([4, 447])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 298]) torch.Size([4, 298])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 385]) torch.Size([4, 385])\n",
            "torch.Size([4, 332]) torch.Size([4, 332])\n",
            "torch.Size([4, 466]) torch.Size([4, 466])\n",
            "torch.Size([4, 415]) torch.Size([4, 415])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 402]) torch.Size([4, 402])\n",
            "torch.Size([4, 373]) torch.Size([4, 373])\n",
            "torch.Size([4, 322]) torch.Size([4, 322])\n",
            "torch.Size([4, 430]) torch.Size([4, 430])\n",
            "torch.Size([4, 353]) torch.Size([4, 353])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 397]) torch.Size([4, 397])\n",
            "torch.Size([4, 408]) torch.Size([4, 408])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 414]) torch.Size([4, 414])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 444]) torch.Size([4, 444])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 409]) torch.Size([4, 409])\n",
            "torch.Size([4, 336]) torch.Size([4, 336])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 381]) torch.Size([4, 381])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 333]) torch.Size([4, 333])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 425]) torch.Size([4, 425])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 337]) torch.Size([4, 337])\n",
            "torch.Size([4, 477]) torch.Size([4, 477])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 370]) torch.Size([4, 370])\n",
            "torch.Size([4, 367]) torch.Size([4, 367])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 460]) torch.Size([4, 460])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 300]) torch.Size([4, 300])\n",
            "torch.Size([4, 390]) torch.Size([4, 390])\n",
            "torch.Size([4, 491]) torch.Size([4, 491])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 267]) torch.Size([4, 267])\n",
            "torch.Size([4, 445]) torch.Size([4, 445])\n",
            "torch.Size([4, 329]) torch.Size([4, 329])\n",
            "torch.Size([4, 499]) torch.Size([4, 499])\n",
            "torch.Size([4, 386]) torch.Size([4, 386])\n",
            "torch.Size([4, 270]) torch.Size([4, 270])\n",
            "torch.Size([4, 474]) torch.Size([4, 474])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 364]) torch.Size([4, 364])\n",
            "torch.Size([4, 442]) torch.Size([4, 442])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 339]) torch.Size([4, 339])\n",
            "torch.Size([4, 433]) torch.Size([4, 433])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 418]) torch.Size([4, 418])\n",
            "torch.Size([4, 393]) torch.Size([4, 393])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 506]) torch.Size([4, 506])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 398]) torch.Size([4, 398])\n",
            "torch.Size([4, 413]) torch.Size([4, 413])\n",
            "torch.Size([4, 343]) torch.Size([4, 343])\n",
            "torch.Size([4, 500]) torch.Size([4, 500])\n",
            "torch.Size([4, 475]) torch.Size([4, 475])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 352]) torch.Size([4, 352])\n",
            "torch.Size([4, 478]) torch.Size([4, 478])\n",
            "torch.Size([4, 494]) torch.Size([4, 494])\n",
            "torch.Size([4, 321]) torch.Size([4, 321])\n",
            "torch.Size([4, 342]) torch.Size([4, 342])\n",
            "torch.Size([4, 484]) torch.Size([4, 484])\n",
            "torch.Size([4, 394]) torch.Size([4, 394])\n",
            "torch.Size([4, 479]) torch.Size([4, 479])\n",
            "torch.Size([4, 453]) torch.Size([4, 453])\n",
            "torch.Size([4, 360]) torch.Size([4, 360])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 289]) torch.Size([4, 289])\n",
            "torch.Size([4, 411]) torch.Size([4, 411])\n",
            "torch.Size([4, 355]) torch.Size([4, 355])\n",
            "torch.Size([4, 395]) torch.Size([4, 395])\n",
            "torch.Size([4, 422]) torch.Size([4, 422])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 292]) torch.Size([4, 292])\n",
            "torch.Size([4, 388]) torch.Size([4, 388])\n",
            "torch.Size([4, 505]) torch.Size([4, 505])\n",
            "torch.Size([4, 410]) torch.Size([4, 410])\n",
            "torch.Size([4, 346]) torch.Size([4, 346])\n",
            "torch.Size([4, 350]) torch.Size([4, 350])\n",
            "torch.Size([4, 412]) torch.Size([4, 412])\n",
            "torch.Size([4, 496]) torch.Size([4, 496])\n",
            "torch.Size([4, 382]) torch.Size([4, 382])\n",
            "torch.Size([4, 320]) torch.Size([4, 320])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 461]) torch.Size([4, 461])\n",
            "torch.Size([4, 400]) torch.Size([4, 400])\n",
            "torch.Size([4, 391]) torch.Size([4, 391])\n",
            "torch.Size([4, 369]) torch.Size([4, 369])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 368]) torch.Size([4, 368])\n",
            "torch.Size([4, 495]) torch.Size([4, 495])\n",
            "torch.Size([4, 401]) torch.Size([4, 401])\n",
            "torch.Size([4, 438]) torch.Size([4, 438])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 379]) torch.Size([4, 379])\n",
            "torch.Size([4, 452]) torch.Size([4, 452])\n",
            "torch.Size([4, 512]) torch.Size([4, 512])\n",
            "torch.Size([4, 374]) torch.Size([4, 374])\n",
            "torch.Size([4, 365]) torch.Size([4, 365])\n",
            "torch.Size([4, 437]) torch.Size([4, 437])\n",
            "torch.Size([4, 419]) torch.Size([4, 419])\n",
            "torch.Size([4, 429]) torch.Size([4, 429])\n",
            "torch.Size([4, 424]) torch.Size([4, 424])\n",
            "torch.Size([4, 473]) torch.Size([4, 473])\n",
            "torch.Size([4, 449]) torch.Size([4, 449])\n",
            "torch.Size([4, 472]) torch.Size([4, 472])\n",
            "torch.Size([4, 357]) torch.Size([4, 357])\n",
            "torch.Size([4, 340]) torch.Size([4, 340])\n",
            "torch.Size([4, 451]) torch.Size([4, 451])\n",
            "torch.Size([4, 349]) torch.Size([4, 349])\n",
            "torch.Size([4, 420]) torch.Size([4, 420])\n",
            "torch.Size([4, 435]) torch.Size([4, 435])\n",
            "torch.Size([4, 293]) torch.Size([4, 293])\n",
            "torch.Size([4, 354]) torch.Size([4, 354])\n",
            "torch.Size([4, 403]) torch.Size([4, 403])\n",
            "torch.Size([4, 407]) torch.Size([4, 407])\n",
            "torch.Size([4, 361]) torch.Size([4, 361])\n",
            "torch.Size([4, 378]) torch.Size([4, 378])\n",
            "torch.Size([4, 334]) torch.Size([4, 334])\n",
            "torch.Size([4, 431]) torch.Size([4, 431])\n",
            "torch.Size([4, 440]) torch.Size([4, 440])\n",
            "torch.Size([4, 396]) torch.Size([4, 396])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 371]) torch.Size([4, 371])\n",
            "torch.Size([4, 489]) torch.Size([4, 489])\n",
            "torch.Size([4, 459]) torch.Size([4, 459])\n",
            "torch.Size([4, 302]) torch.Size([4, 302])\n",
            "torch.Size([4, 383]) torch.Size([4, 383])\n",
            "torch.Size([4, 509]) torch.Size([4, 509])\n",
            "torch.Size([4, 257]) torch.Size([4, 257])\n",
            "torch.Size([4, 359]) torch.Size([4, 359])\n",
            "torch.Size([4, 384]) torch.Size([4, 384])\n",
            "torch.Size([4, 294]) torch.Size([4, 294])\n",
            "torch.Size([4, 446]) torch.Size([4, 446])\n",
            "torch.Size([4, 426]) torch.Size([4, 426])\n",
            "torch.Size([4, 458]) torch.Size([4, 458])\n"
          ]
        }
      ],
      "source": [
        "print(\"Train loader:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "03a1b5ca",
      "metadata": {
        "collapsed": true,
        "id": "03a1b5ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Input Shape: torch.Size([4, 399])\n",
            "Batch Labels Shape: torch.Size([4, 399])\n",
            "\n",
            "--- Πρώτο Δείγμα (Decoded) ---\n",
            "tensor([50256,    35, 29267,    25,   198, 26069,  1377, 18300,   257,    14,\n",
            "        16469,    12, 18769,    12, 16302,    14, 16469,    12, 18769,    14,\n",
            "        10677,    14, 12417,    14, 12355,    14,  2398,    14, 16469, 30604,\n",
            "           14, 18769,    14, 12384,    14, 16366,    14, 19452, 30800, 32875,\n",
            "           13, 12355,   275,    14, 16469,    12, 18769,    12, 16302,    14,\n",
            "        16469,    12, 18769,    14, 10677,    14, 12417,    14, 12355,    14,\n",
            "         2398,    14, 16469, 30604,    14, 18769,    14, 12384,    14, 16366,\n",
            "           14, 19452, 30800, 32875,    13, 12355,   198,  9630,  1279,    39,\n",
            "        11211,    29,   492,    27,    39, 11211,    29,  1802, 29173,   198,\n",
            "         6329,   257,    14, 16469,    12, 18769,    12, 16302,    14, 16469,\n",
            "           12, 18769,    14, 10677,    14, 12417,    14, 12355,    14,  2398,\n",
            "           14, 16469, 30604,    14, 18769,    14, 12384,    14, 16366,    14,\n",
            "        19452, 30800, 32875,    13, 12355,   198, 45340,   275,    14, 16469,\n",
            "           12, 18769,    12, 16302,    14, 16469,    12, 18769,    14, 10677,\n",
            "           14, 12417,    14, 12355,    14,  2398,    14, 16469, 30604,    14,\n",
            "        18769,    14, 12384,    14, 16366,    14, 19452, 30800, 32875,    13,\n",
            "        12355,   198, 12404,   532, 29088,    11,    21,  1343, 29088,    11,\n",
            "           22, 25248,  1171,  1398,  8324, 30800, 32875,  1391,   198,   220,\n",
            "          197,  1635,  2488, 10378, 31023,  1201,   362,    13,    16,    13,\n",
            "           15,   287,  2661,   286,   198,   220,   197,  1635,  1391,    31,\n",
            "         8726,  1303, 35487, 47649,  3299,     7, 10100, 20579,    11, 10903,\n",
            "         9206, 38165,   198,   220,   197,  9466,   198,    10,   197,    31,\n",
            "        12156, 31023,   198,   220,   197, 11377,  8324, 30800, 32875,  4096,\n",
            "        13838,  1634,     7, 10100, 20579,    11, 10903,  9206,     8,  1391,\n",
            "          198,   220,   197,   197,  7783,  4096, 47649,  3299,     7, 29460,\n",
            "           11,  9206,  1776,   198,   220,   197,    92,   198,   198,  9858,\n",
            "        36393,   337,  1546,  4090,  8264,    25,   198,  4550,  4814,  2488,\n",
            "        12156, 31023, 23025,   198,  2601,  4629, 24997,    12,    27,    40,\n",
            "           29, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "       device='cuda:0')\n",
            "\n",
            "--- Labels (για να δεις το Masking με -100) ---\n",
            "tensor([   35, 29267,    25,   198, 26069,  1377, 18300,   257,    14, 16469,\n",
            "           12, 18769,    12, 16302,    14, 16469,    12, 18769,    14, 10677,\n",
            "           14, 12417,    14, 12355,    14,  2398,    14, 16469, 30604,    14,\n",
            "        18769,    14, 12384,    14, 16366,    14, 19452, 30800, 32875,    13,\n",
            "        12355,   275,    14, 16469,    12, 18769,    12, 16302,    14, 16469,\n",
            "           12, 18769,    14, 10677,    14, 12417,    14, 12355,    14,  2398,\n",
            "           14, 16469, 30604,    14, 18769,    14, 12384,    14, 16366,    14,\n",
            "        19452, 30800, 32875,    13, 12355,   198,  9630,  1279,    39, 11211,\n",
            "           29,   492,    27,    39, 11211,    29,  1802, 29173,   198,  6329,\n",
            "          257,    14, 16469,    12, 18769,    12, 16302,    14, 16469,    12,\n",
            "        18769,    14, 10677,    14, 12417,    14, 12355,    14,  2398,    14,\n",
            "        16469, 30604,    14, 18769,    14, 12384,    14, 16366,    14, 19452,\n",
            "        30800, 32875,    13, 12355,   198, 45340,   275,    14, 16469,    12,\n",
            "        18769,    12, 16302,    14, 16469,    12, 18769,    14, 10677,    14,\n",
            "        12417,    14, 12355,    14,  2398,    14, 16469, 30604,    14, 18769,\n",
            "           14, 12384,    14, 16366,    14, 19452, 30800, 32875,    13, 12355,\n",
            "          198, 12404,   532, 29088,    11,    21,  1343, 29088,    11,    22,\n",
            "        25248,  1171,  1398,  8324, 30800, 32875,  1391,   198,   220,   197,\n",
            "         1635,  2488, 10378, 31023,  1201,   362,    13,    16,    13,    15,\n",
            "          287,  2661,   286,   198,   220,   197,  1635,  1391,    31,  8726,\n",
            "         1303, 35487, 47649,  3299,     7, 10100, 20579,    11, 10903,  9206,\n",
            "        38165,   198,   220,   197,  9466,   198,    10,   197,    31, 12156,\n",
            "        31023,   198,   220,   197, 11377,  8324, 30800, 32875,  4096, 13838,\n",
            "         1634,     7, 10100, 20579,    11, 10903,  9206,     8,  1391,   198,\n",
            "          220,   197,   197,  7783,  4096, 47649,  3299,     7, 29460,    11,\n",
            "         9206,  1776,   198,   220,   197,    92,   198,   198,  9858, 36393,\n",
            "          337,  1546,  4090,  8264,    25,   198,  4550,  4814,  2488, 12156,\n",
            "        31023, 23025,   198,  2601,  4629, 24997,    12,    27,    40,    29,\n",
            "        50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# 1. Παίρνουμε το πρώτο batch\n",
        "first_batch = next(iter(train_loader))\n",
        "\n",
        "# 2. Αποσυμπλέκουμε τα δεδομένα (input_ids και labels)\n",
        "input_ids, labels = first_batch\n",
        "\n",
        "print(f\"Batch Input Shape: {input_ids.shape}\")\n",
        "print(f\"Batch Labels Shape: {labels.shape}\")\n",
        "\n",
        "# 3. Δες το πρώτο δείγμα του batch σε μορφή κειμένου\n",
        "sample_index = 0\n",
        "decoded_text = tokenizer.decode(input_ids[sample_index], skip_special_tokens=False)\n",
        "\n",
        "print(\"\\n--- Πρώτο Δείγμα (Decoded) ---\")\n",
        "print(input_ids[sample_index])\n",
        "\n",
        "print(\"\\n--- Labels (για να δεις το Masking με -100) ---\")\n",
        "print(labels[sample_index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "015fb7b4",
      "metadata": {
        "collapsed": true,
        "id": "015fb7b4"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(targets[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "dbef220d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbef220d",
        "outputId": "cede387b-30c9-48f6-a1eb-d8511c39dcdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50257\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "model.config.pad_token_id = tokenizer.eos_token_id\n",
        "model.config.use_cache = False\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "print(tokenizer.vocab_size)\n",
        "model.config.pad_token_id\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "271512b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "271512b0",
        "outputId": "0f68e404-32f6-48bb-88f8-096eef2cbeec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"dtype\": \"float32\",\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"pad_token_id\": 50256,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.57.6\",\n",
            "  \"use_cache\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(model.config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ed2cc5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "de90183fff1b4cf4a0862fe1c9fe62ef",
            "48b6e1877b2c49c9bc1b8b9fc51dd53b",
            "f262f30aef634b2cb490ed250f2fdde2",
            "057e8e4430d64f25b5294903d062369d",
            "f87e68a2b1be4ede9217ecf0ea2e2da9",
            "c14f83c26ab64ebfb0839a2ef10b663a",
            "6f61885f6b7d4a71b8804285cf9802ba",
            "93c9bb8fb04442cab7693302f6411458",
            "17cfad8f10384cfb85a81e2ef100f0ce",
            "256ec936d1ce4513b17cb09fa055d449",
            "5c284bbab3cd481d9168f18c72e92901",
            "84bcb37019bd43e789a8c5c3bbe8fa65",
            "e9fcef0e4faa4bbbad3fc33a4809b7ad",
            "db83a6358e34495d82cc4dc8ad2e188e",
            "be789e4225c54bbfb35916dc598fb6ea",
            "78961a27e14b41558ee813670c1a7780",
            "e30bcadf148a458e97b83fd48158a05d",
            "e6c97330b8424ba6ade65aee4920efed",
            "dce1237f66864694bbdd786286be4aba",
            "219f986690a6494faa7f03ab475cf437",
            "3b143e9f25c34c0587c8712e2a0feaaa",
            "9c537a0a6f6a4a6390d366511259f673"
          ]
        },
        "id": "e5ed2cc5",
        "outputId": "0b59f9bb-387b-4094-cc77-d5bb461dbbda"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0d5ebaf7d6e4b0e8dfd8f9f94feecf9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/3:   0%|          | 0/23068 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/stryker.conf.js b/stryker.conf.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/stryker.conf.js\n",
            "+++ b/stryker.conf.js\n",
            "@@ -23,9 +23,7 @@ module.exports = function(config) {\n",
            "     },\n",
            "     mutate: [\n",
            "    ...\n",
            "\n",
            "ACTUAL MESSAGE: CA-<I> Adding back in mutation for models\n",
            "GENERATED MESSAGE: -- ( ) .md is not used here because this file uses it instead of the `modules` directive; but if you want to use that format in your CSS files then there's no need for\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/python/ray/rllib/agents/ars/ars.py b/python/ray/rllib/agents/ars/ars.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/python/ray/rllib/agents/ars/ars.py\n",
            "+++ b/python/ray/rllib/agents/ars/ars.py\n",
            "@@ -2...\n",
            "\n",
            "ACTUAL MESSAGE: Ars increase (#<I>)\n",
            "\n",
            "* removed cv2\n",
            "\n",
            "\n",
            "\n",
            "* remove opencv\n",
            "\n",
            "\n",
            "\n",
            "* increased number of default rollouts ARS\n",
            "\n",
            "\n",
            "\n",
            "* put cv2 back in this branch\n",
            "\n",
            "\n",
            "\n",
            "* put cv2 back in this branch\n",
            "\n",
            "\n",
            "\n",
            "* moved cv2 back where it belongs in preprocessors\n",
            "GENERATED MESSAGE: \"\"\" Create module for python functions and properties \"\"\" . __name__( self , ) def get(): return Response object if response == None : import os print (response) else { ctx['ex\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/weblib.php b/lib/weblib.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/weblib.php\n",
            "+++ b/lib/weblib.php\n",
            "@@ -3788,12 +3788,12 @@ function print_user_picture($user, $courseid, $picture=NULL, ...\n",
            "\n",
            "ACTUAL MESSAGE: Small efficiency improvement for print_user_picture() when it does access the db\n",
            "GENERATED MESSAGE: MISSILE REVIEW! !== 1UP !!!!! NO MORE HACKS THIS WEEK!!\n",
            "\n",
            "*Update 2 (9pm EST)- Updated for release : https://githubusercontent .com\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/obdalib/obdalib-core/src/main/java/inf/unibz/it/obda/gui/swing/mapping/panel/MappingManagerPanel.java b/obdalib/obdalib-core/src/main/java/inf/unibz/it/obda/gui/swing/mapping/panel/Mappin...\n",
            "\n",
            "ACTUAL MESSAGE: Users have to select the data source first before inserting a new mapping.\n",
            "\n",
            "BUG=<I>\n",
            "\n",
            "Ticket URL: <URL>\n",
            "GENERATED MESSAGE: {\n",
            "NETWORK\\CurrentVersion=10.0 and Visual Studio 2015 R2 is required for this implementation to work! Don't worry about it breaking your IDE or you'll get rejected in\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/index.js b/index.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/index.js\n",
            "+++ b/index.js\n",
            "@@ -242,7 +242,11 @@ class Hyperdrive extends Nanoresource {\n",
            " \n",
            "     function onkey (publicKey) {\n",
            "       const...\n",
            "\n",
            "ACTUAL MESSAGE: Add error handling around malformed content feed loads\n",
            "GENERATED MESSAGE: If the path does not already exist at compile time it is possible to implement this method using only static imports as provided in _main() and then call super::do_node install () . All of\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/wyil/transforms/FunctionCheck.java b/src/wyil/transforms/FunctionCheck.java\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/src/wyil/transforms/FunctionCheck.java\n",
            "+++ b/src/wyil/transforms/Function...\n",
            "\n",
            "ACTUAL MESSAGE: Minor tweaks to FunctionCheck to make sure it checks for internal message sends.\n",
            "GENERATED MESSAGE: I'm still not happy with this example and I really don't want to write another one that uses more of it but since the solution is so simple why bother? Hopefully they'll help someone out in\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/ol/renderer/canvas/canvasvectorlayerrenderer.js b/src/ol/renderer/canvas/canvasvectorlayerrenderer.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/ol/renderer/canvas/canvasvectorlayerrendere...\n",
            "\n",
            "ACTUAL MESSAGE: Adding comment about MIN_RESOLUTION\n",
            "GENERATED MESSAGE: The last bug report on http:/freedesktoplinux.org was written by Jason Susskind and fixed the following issues(not included here are these):\n",
            "\n",
            "- Fixed two wrong offsets (\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/source/loaders.js b/source/loaders.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/source/loaders.js\n",
            "+++ b/source/loaders.js\n",
            "@@ -22,6 +22,9 @@ export function find_style_rules(configuration)\n",
            " \t\tcons...\n",
            "\n",
            "ACTUAL MESSAGE: `extract-text-webpack-plugin` path comments added\n",
            "GENERATED MESSAGE: Add the configurable prefix of an extensibility module to CSS on top Of Webpack plugin extensions , so that webp will know how this can be overridden using stylesheet filters (#http://\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/servlet/src/main/java/io/undertow/servlet/core/DeploymentManagerImpl.java b/servlet/src/main/java/io/undertow/servlet/core/DeploymentManagerImpl.java\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/ser...\n",
            "\n",
            "ACTUAL MESSAGE: UNDERTOW-<I> Listener instances not released on undeploy\n",
            "GENERATED MESSAGE: Fix dependency in Servlet's init method for non-null values when initializer used with no nulls on failure if initialization fails to execute due process of running code after startup via service hook (or\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/test.js b/test.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/test.js\n",
            "+++ b/test.js\n",
            "@@ -875,6 +875,10 @@ test('word assembler directive label', (t) => {\n",
            "   t.equal(machine_code[1], 3);    // .word ...\n",
            "\n",
            "ACTUAL MESSAGE: Test assembler out-of-range .tryte and .word\n",
            "GENERATED MESSAGE: Use `toString' to ensure only one name is passed in when compiling with the same module as for target language version 2 or later? https://developer-cpanelswiki;-)#\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/aranea/failure_repository.rb b/lib/aranea/failure_repository.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/aranea/failure_repository.rb\n",
            "+++ b/lib/aranea/failure_repository.rb\n",
            "@@ -33,8 +33,...\n",
            "\n",
            "ACTUAL MESSAGE: [MCC-<I>] Setting default response/response_header to empty hash\n",
            "GENERATED MESSAGE: * fix error for passwd in reccomendations of rbencode files without name argument (e.: https://githubusercontent.,com/) but I think it was good and now needs more\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/cli/cli.js b/lib/cli/cli.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/cli/cli.js\n",
            "+++ b/lib/cli/cli.js\n",
            "@@ -115,6 +115,14 @@ function validateInput(argv) {\n",
            "   if (\n",
            "     argv.browsertime.saf...\n",
            "\n",
            "ACTUAL MESSAGE: Guard if you try to run Safari in Docker (#<I>)\n",
            "GENERATED MESSAGE: [I] Fix support for non-default running browsers based upon port range of macOS by default using `svc` instead xorq with _macOS' compatibility mode enabled as well :) [\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/packages/firestore/tools/console.build.js b/packages/firestore/tools/console.build.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/packages/firestore/tools/console.build.js\n",
            "+++ b/packages/firestore/...\n",
            "\n",
            "ACTUAL MESSAGE: Fix import for node resolve for console build (#<I>)\n",
            "GENERATED MESSAGE: Fix log file for missing eps module and config with jasmine 2 support from dnf8dev @petervogeler https://githubusercontent's/goofbundle\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/code/MSSQLDatabase.php b/code/MSSQLDatabase.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/code/MSSQLDatabase.php\n",
            "+++ b/code/MSSQLDatabase.php\n",
            "@@ -130,14 +130,14 @@ class MSSQLDatabase extends SS_...\n",
            "\n",
            "ACTUAL MESSAGE: BUGFIX: re-enabling MARS, framework assumes it can run DB::query without fetching the results, which leaves the result set open and prohibits executing another query in the mean time\n",
            "GENERATED MESSAGE: fixed error checking in MySQL module when creating database with new connection info on first attempt (changed from fix@bugzilla#90545). Fixed failure exception handling and failed to connect through HTTP server rather\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/appsignal/version.rb b/lib/appsignal/version.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/appsignal/version.rb\n",
            "+++ b/lib/appsignal/version.rb\n",
            "@@ -1,5 +1,5 @@\n",
            " require 'yaml'\n",
            " \n",
            " module App...\n",
            "\n",
            "ACTUAL MESSAGE: Bump to <I>.beta<I> [ci skip]\n",
            "GENERATED MESSAGE: fix issue with app signing on windows only (unexpected behavior for OS X) and that means it is not signed correctly in iOS8? Thanks Jürgen Kallbrün !! ;)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/testserver/uaa.go b/testserver/uaa.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/testserver/uaa.go\n",
            "+++ b/testserver/uaa.go\n",
            "@@ -49,12 +49,13 @@ func NewUAA() *UAA {\n",
            " \n",
            " \trouter := mux.NewRouter()\n",
            " \t...\n",
            "\n",
            "ACTUAL MESSAGE: Include private signing key when booting testserver UAA\n",
            "GENERATED MESSAGE: Fixing default auth provider for uaa server setup in UTAA servers (thanks to Jadah @ http://githubusercontent!com/​jdkwagutteykappelu\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/spec/unit/settings_spec.rb b/spec/unit/settings_spec.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/spec/unit/settings_spec.rb\n",
            "+++ b/spec/unit/settings_spec.rb\n",
            "@@ -1308,10 +1308,9 @@ describe Puppe...\n",
            "\n",
            "ACTUAL MESSAGE: (PUP-<I>) Make settings_spec for windows specific test conditional\n",
            "\n",
            "In settings_spec, there were a test that simulated running on windows by\n",
            "mocking the windows_feature to true. This used to work but now with app\n",
            "management on by default, there is more activity in the setup. This in\n",
            "turn leads to puppet wanting to load things that are not initialized in\n",
            "the Util::Windows name space.\n",
            "\n",
            "For that reason, the windows specific test in settings was made\n",
            "conditional on the windows feature.\n",
            "GENERATED MESSAGE: Removed missing options from the configure process (#requires #sshrc), fix issue where to define settings and not have them in configfile for testing purposes!#[allow]*v1b7d\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/bundle.js b/bundle.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/bundle.js\n",
            "+++ b/bundle.js\n",
            "@@ -31186,7 +31186,8 @@ function through (write, end, opts) {\n",
            "             next.done = false;\n",
            "           ...\n",
            "\n",
            "ACTUAL MESSAGE: Pull in fix for regeneratorRuntime.values (#<I>).\n",
            "GENERATED MESSAGE: Fixed missing options argument in new file to ensure use of `next`. (#c4d0a5f2e6). #cdnpoole is already on npm's master branch and it\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/Network/Session/DatabaseSession.php b/src/Network/Session/DatabaseSession.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/Network/Session/DatabaseSession.php\n",
            "+++ b/src/Network/Session/Datab...\n",
            "\n",
            "ACTUAL MESSAGE: Making sure the database sessions adapter never returns false\n",
            "\n",
            "We had a similar problem with a custom sessions adapter at work, and this change fixed it\n",
            "\n",
            "\n",
            "\n",
            "Fixes #<I>\n",
            "GENERATED MESSAGE: Removed SQL in \"database\" session provider and removed callbacks to stdout() function from the result data table (#1). All that was done is remove deprecated nullptr functions after we've passed it\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/Less/Parser.php b/lib/Less/Parser.php\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/lib/Less/Parser.php\n",
            "+++ b/lib/Less/Parser.php\n",
            "@@ -228,6 +228,10 @@ class Less_Parser extends Less_Cache{\n",
            " \t\t$ru...\n",
            "\n",
            "ACTUAL MESSAGE: free up memory in GetRules()\n",
            "GENERATED MESSAGE: Remove unused file in parse primary (in case we were unable to find one). The issue with that is it overwrites an existing configuration instance after running this program before parsing from its parent database page (#\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/ember-cli-spinjs.js b/lib/ember-cli-spinjs.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/ember-cli-spinjs.js\n",
            "+++ b/lib/ember-cli-spinjs.js\n",
            "@@ -21,7 +21,7 @@ EmberCLISpinjs.prototype.treeFo...\n",
            "\n",
            "ACTUAL MESSAGE: moved the lookup of spinjs to vendor-addon\n",
            "GENERATED MESSAGE: Ember CLI spinjs adds support for import and install in component nodes (#requires jscore). The change is purely due to the fact that it does not affect branch trees yet as they are now listed\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/buildbucket/cmd/bbagent/build_client.go b/buildbucket/cmd/bbagent/build_client.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/buildbucket/cmd/bbagent/build_client.go\n",
            "+++ b/buildbucket/cmd/bbagent/b...\n",
            "\n",
            "ACTUAL MESSAGE: [bbagent] Rate limit UpdateBuild calls to 1/3Hz\n",
            "\n",
            "We hope this helps with datastore contention observed in UpdateBuild.\n",
            "\n",
            "R=ddoman, tandrii\n",
            "\n",
            "Bug: <I>\n",
            "Change-Id: If<I>cd<I>fa<I>f<I>fa<I>ca<I>c9ef<I>ba5\n",
            "Reviewed-on: <URL>\n",
            "GENERATED MESSAGE: Fix call to dropFnc of stream type in async request handler (#935). Fixes nil on unacceptably long value streams and closes bug #846 (see commit ee0fce\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/extract-intl.js b/extract-intl.js\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/extract-intl.js\n",
            "+++ b/extract-intl.js\n",
            "@@ -47,7 +47,7 @@ const { presets, plugins } = babelConfig;\n",
            " // Resolve the absol...\n",
            "\n",
            "ACTUAL MESSAGE: feat: add support for es language\n",
            "GENERATED MESSAGE: removed extra step from #define as it has been removed with add_version (e) and fixes (#see comments for details). If you have read this commit please update all relevant sections accordingly if\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/pypika/__init__.py b/pypika/__init__.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/pypika/__init__.py\n",
            "+++ b/pypika/__init__.py\n",
            "@@ -38,4 +38,4 @@ from .utils import JoinException, GroupingException...\n",
            "\n",
            "ACTUAL MESSAGE: Increased version to <I>\n",
            "GENERATED MESSAGE: Added 'PEPHA' variable for Python 3 support in pymka # https://githubusercontent(tm)blogspotify/?tag=3dc7bccf8c6bc14\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/jenetics.incubator/src/test/java/io/jenetics/incubator/parser/BnfParserTest.java b/jenetics.incubator/src/test/java/io/jenetics/incubator/parser/BnfParserTest.java\n",
            "index <HASH>..<HASH> 10...\n",
            "\n",
            "ACTUAL MESSAGE: #<I>: Fix tests.\n",
            "GENERATED MESSAGE: fix #3954 with invalid test for tokenizers being null (#4110). (Replaced \"isValid\" to \"_valid\") @revert = idiom#3859 [REPEAT\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/Entity/AttributeValueFieldTrait.php b/Entity/AttributeValueFieldTrait.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/Entity/AttributeValueFieldTrait.php\n",
            "+++ b/Entity/AttributeValueFieldTrait.php\n",
            "@...\n",
            "\n",
            "ACTUAL MESSAGE: moved UserAttributeValue::getValue to field trait\n",
            "GENERATED MESSAGE: Fix missing type check for attributes that are not set to null by PHPUnit specifier (#5906) (thanks @cwajorner). Note the use of 'null' on variables whose\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/Xml/QuipXmlElement.php b/src/Xml/QuipXmlElement.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/Xml/QuipXmlElement.php\n",
            "+++ b/src/Xml/QuipXmlElement.php\n",
            "@@ -63,8 +63,15 @@ class QuipXmlEleme...\n",
            "\n",
            "ACTUAL MESSAGE: Refactored append() to address travis build error.\n",
            "GENERATED MESSAGE: Fix bug with nested XML elements in element array on parent (#requires @gosh).#fix/#previousMesseousy #no new comment for this test and only to avoid comments\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/app.go b/app.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/app.go\n",
            "+++ b/app.go\n",
            "@@ -77,8 +77,7 @@ func NewApp() *App {\n",
            " }\n",
            " \n",
            " // Entry point to the cli app. Parses the arguments slice and routes to ...\n",
            "\n",
            "ACTUAL MESSAGE: After handler brought up to speed.\n",
            "\n",
            "As discussed in issue #<I>, I modified the implementation to be simpler.\n",
            "I checked how to propagate err, being done with a scope trick. From our\n",
            "deferred function we cannot return a new value, so we override the \"default\"\n",
            "return value (err), declared on functions' declarations.\n",
            "\n",
            "Check this StackOverflow for more info: <URL>\n",
            "GENERATED MESSAGE: Make args into more efficient CVS scripts by including some extra helper method for getting CLI info from stdout in cmds instead of just passing it directly as an argument that can be accessed later via get\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/qa_tests/_utils.py b/qa_tests/_utils.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/qa_tests/_utils.py\n",
            "+++ b/qa_tests/_utils.py\n",
            "@@ -15,6 +15,8 @@\n",
            " \n",
            " import unittest\n",
            " \n",
            "+from lxml import etree\n",
            "+\n",
            " fro...\n",
            "\n",
            "ACTUAL MESSAGE: qa_tests/_utils:\n",
            "\n",
            "Added a util method for testing XML artifacts for equality.\n",
            "GENERATED MESSAGE: Added test that does not need special input (#{1} is better than #{4}) because of lacklustre Python support (see http://googlesourceware.com/#!/test\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/Factory/CurrencyFactory.php b/Factory/CurrencyFactory.php\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/Factory/CurrencyFactory.php\n",
            "+++ b/Factory/CurrencyFactory.php\n",
            "@@ -34,7 +34,6 @@ class CurrencyF...\n",
            "\n",
            "ACTUAL MESSAGE: Added rule required to all forms\n",
            "\n",
            "(cherry picked from commit 0ffd7c3b<I>f<I>d<I>bf9b<I>bebeb<I>)\n",
            "GENERATED MESSAGE: fix missing comma to capitalization (#37) #39 at BSN change for clarity.* Thanks jenkins@github! This fix should be merged into the current stable release of currency code (B\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/Form/Badge/BadgeType.php b/Form/Badge/BadgeType.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/Form/Badge/BadgeType.php\n",
            "+++ b/Form/Badge/BadgeType.php\n",
            "@@ -61,7 +61,8 @@ class BadgeType extends Abs...\n",
            "\n",
            "ACTUAL MESSAGE: [CoreBundle] Adding limit on version field to avoid version inferior to 1\n",
            "GENERATED MESSAGE: Adding automatic award validation to badge types (#[no active] warning). Only validate if the selected category has an auto_awarded attribute (or otherwise not applicable when it is disabled in form data),\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/models/elements.model.mongodb.js b/src/models/elements.model.mongodb.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/models/elements.model.mongodb.js\n",
            "+++ b/src/models/elements.model.mongodb....\n",
            "\n",
            "ACTUAL MESSAGE: Try to optimize some Mongo queries with compound indexes\n",
            "GENERATED MESSAGE: Fixed this issue after changing base class in version v8 of MongoODB instance API implementation to use the new model backend by default (#[macro-lang]): fix #176038#\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/cloudmesh/common/Shell.py b/cloudmesh/common/Shell.py\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/cloudmesh/common/Shell.py\n",
            "+++ b/cloudmesh/common/Shell.py\n",
            "@@ -25,6 +25,17 @@ import psutil\n",
            " import ...\n",
            "\n",
            "ACTUAL MESSAGE: add decorator hint that may or may not work\n",
            "GENERATED MESSAGE: added notImpeachableCommand to the standard shell package (#v4302). Only used on Unix platforms as well... it will never be able read string files (i.e., strings that have\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/Eloquent/Model.php b/Eloquent/Model.php\n",
            "index <HASH>..<HASH> 100755\n",
            "--- a/Eloquent/Model.php\n",
            "+++ b/Eloquent/Model.php\n",
            "@@ -1300,6 +1300,16 @@ abstract class Model implements ArrayAccess, A...\n",
            "\n",
            "ACTUAL MESSAGE: Added new `trashed` method to Eloquent model to determine if model has been soft deleted.\n",
            "GENERATED MESSAGE: Added docstring to find hard deleted fields when using auto delete instead of array access on factory objects (as in case \"old\" database doesn't support this option): Added docs from bug#4156\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/package/examples/UnusedFieldTransform.js b/src/package/examples/UnusedFieldTransform.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/package/examples/UnusedFieldTransform.js\n",
            "+++ b/src/packag...\n",
            "\n",
            "ACTUAL MESSAGE: change example jar path to command line arg in example\n",
            "GENERATED MESSAGE: Fixes bug on unpack command since it is not yet possible to extract object from the directory of your own dir so some path would have been required after unpacking and reusing jar into this project\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/isort/settings.py b/isort/settings.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/isort/settings.py\n",
            "+++ b/isort/settings.py\n",
            "@@ -107,7 +107,10 @@ def _update_settings_with_config(path, name, default...\n",
            "\n",
            "ACTUAL MESSAGE: Stop looking for config files once we hit the filesystem root.\n",
            "GENERATED MESSAGE: Use \"no config file is found\" instead of \"files in the system directory\", it's really better to force each one from being specified when starting up an account with Python 2 than relying on external\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/docroot/modules/custom/ymca_mindbody/src/Form/MindbodyPOCForm.php b/docroot/modules/custom/ymca_mindbody/src/Form/MindbodyPOCForm.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/docroot/modules/cus...\n",
            "\n",
            "ACTUAL MESSAGE: [YPTF-<I>][YPTF-<I>] Add Personal Training form and it's results page with theming\n",
            "GENERATED MESSAGE: Moved #NAME from field to trigger element when specifying it as a context in formatter template since the value is currently undefined (i see https://githubusercontent.\")/msgq5e/.[\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/modules/admin/src/image/Item.php b/modules/admin/src/image/Item.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/modules/admin/src/image/Item.php\n",
            "+++ b/modules/admin/src/image/Item.php\n",
            "@@ -90,10 +90...\n",
            "\n",
            "ACTUAL MESSAGE: fix $scheme according to yii url helper\n",
            "GENERATED MESSAGE: fix typo in route method (#https://githubusercontent...puppetlint...). Fixes #49 of #53\n",
            "* Fix 'yib' module being ignored after removing any other sources already available\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/epuber/compiler/file_database.rb b/lib/epuber/compiler/file_database.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/epuber/compiler/file_database.rb\n",
            "+++ b/lib/epuber/compiler/file_database....\n",
            "\n",
            "ACTUAL MESSAGE: [FileDatabase] fix weird crash when @all_files is false\n",
            "GENERATED MESSAGE: Fix issue with JSON in file database loaders (#18). Added json to the filename and saved it before storing any data (since there's nothing on the filesystem of course...) so when I use the\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/main/java/org/osiam/client/oauth/AuthService.java b/src/main/java/org/osiam/client/oauth/AuthService.java\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/main/java/org/osiam/client/oauth/AuthSe...\n",
            "\n",
            "ACTUAL MESSAGE: [cleanup] making final what has to be final\n",
            "GENERATED MESSAGE: add new clients for auth service and create redirect uri to API (#webmaster@bugs.go)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/message.go b/message.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/message.go\n",
            "+++ b/message.go\n",
            "@@ -169,7 +169,7 @@ const (\n",
            " type URI string\n",
            " \n",
            " // An ID is a unique, non-negative number. Different ...\n",
            "\n",
            "ACTUAL MESSAGE: Change ID type to uint<I>\n",
            "\n",
            "* ID values would overflow on a <I>-bit platform\n",
            "GENERATED MESSAGE: fix issues with URIs as integer types only in strings (#8)[v1].*#<I>] fixed #4[rev2): fix issue that could be triggered by adding an extra u\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/scss_lint/linter/property_units.rb b/lib/scss_lint/linter/property_units.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/scss_lint/linter/property_units.rb\n",
            "+++ b/lib/scss_lint/linter/propert...\n",
            "\n",
            "ACTUAL MESSAGE: Comment regex in PropertyUnits linter\n",
            "\n",
            "I wanted to make this code easier to understand, so I broke this regex\n",
            "down and added some comments.\n",
            "GENERATED MESSAGE: fixing parsing error for integer operators in regexp (#<I>)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/Tools/build-translation.js b/Tools/build-translation.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/Tools/build-translation.js\n",
            "+++ b/Tools/build-translation.js\n",
            "@@ -156,6 +156,11 @@ async function t...\n",
            "\n",
            "ACTUAL MESSAGE: build-translation.js: hack to show en_US as <I>% (#<I>)\n",
            "GENERATED MESSAGE: fix in translationStatus() that would not happen if the user typed \"nocorrect\" into the query string instead of its actual filename at the end ;) fix[--release].php... (#<<\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/isono/event_router.rb b/lib/isono/event_router.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/isono/event_router.rb\n",
            "+++ b/lib/isono/event_router.rb\n",
            "@@ -5,14 +5,17 @@ module Isono\n",
            "     Chann...\n",
            "\n",
            "ACTUAL MESSAGE: event_channel: pass through if EventChannel was not initialized.\n",
            "GENERATED MESSAGE: Add new example from @dexeldayr in my editor for events without active channel (#[BETA]).#<I>)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/opal/corelib/runtime.js b/opal/corelib/runtime.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/opal/corelib/runtime.js\n",
            "+++ b/opal/corelib/runtime.js\n",
            "@@ -438,7 +438,7 @@\n",
            "     if (superclass != null) ...\n",
            "\n",
            "ACTUAL MESSAGE: Inherit singleton class for Module subclasses too\n",
            "\n",
            "This check was probably a legacy of the old module system that was not as reliable.\n",
            "GENERATED MESSAGE: Update the template in runtime code to use superclass instead of superclass on subclasses as well. This is necessary for some purposes and should not cause performance issues when working with other classes being built like\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/spec/lib/flapjack/pikelet_spec.rb b/spec/lib/flapjack/pikelet_spec.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/spec/lib/flapjack/pikelet_spec.rb\n",
            "+++ b/spec/lib/flapjack/pikelet_spec.rb\n",
            "@@ -60,6 ...\n",
            "\n",
            "ACTUAL MESSAGE: Update pikelet_spec to check 'bind_address' config option\n",
            "GENERATED MESSAGE: Don't return when it doesn't have a name or is empty (#[test]#{test}), so throw an error on the assertion failure message if the name was already in scope at\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/core/src/main/java/org/testcontainers/containers/GenericContainer.java b/core/src/main/java/org/testcontainers/containers/GenericContainer.java\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/core/src/...\n",
            "\n",
            "ACTUAL MESSAGE: change exec's log level to DEBUG from INFO\n",
            "GENERATED MESSAGE: [SELF] Move to `exec` option of new generic container by adding the ExecExec command as it will get executed when running more than one call on containers after creating that unit test in <\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/compress/versioning/mtime/__init__.py b/compress/versioning/mtime/__init__.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/compress/versioning/mtime/__init__.py\n",
            "+++ b/compress/versioning/mtime/__ini...\n",
            "\n",
            "ACTUAL MESSAGE: changed variable name `on` to `output_file_name`\n",
            "GENERATED MESSAGE: Fixes build #24 of M2K1 (#2867) to allow for more debug builds when building older versions with stable release notes.*\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/discordrb/voice/voice_bot.rb b/lib/discordrb/voice/voice_bot.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/discordrb/voice/voice_bot.rb\n",
            "+++ b/lib/discordrb/voice/voice_bot.rb\n",
            "@@ -1,5 +1,6 ...\n",
            "\n",
            "ACTUAL MESSAGE: Log VoiceBot initialization errors to console\n",
            "GENERATED MESSAGE: added message to Discord on success after successfully receiving an email from Discord.\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/py/conftest.py b/py/conftest.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/py/conftest.py\n",
            "+++ b/py/conftest.py\n",
            "@@ -189,7 +189,7 @@ def server(request):\n",
            " \n",
            "     _host = 'localhost'\n",
            "     _port = 4444...\n",
            "\n",
            "ACTUAL MESSAGE: [py] Fixing remote tests, migrating from buck to bazel\n",
            "GENERATED MESSAGE: fix for delay on #<I> (#<I>)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/auto_network/plugin.rb b/lib/auto_network/plugin.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/auto_network/plugin.rb\n",
            "+++ b/lib/auto_network/plugin.rb\n",
            "@@ -25,6 +25,11 @@ module AutoNetwork...\n",
            "\n",
            "ACTUAL MESSAGE: Release addresses allocated by VirtualBox UUID\n",
            "\n",
            "This is a partial revert of 9b7a<I> as it restores a `hook.before` on\n",
            "`VagrantPlugins::ProviderVirtualBox::Action::Destroy`. This allows us to\n",
            "release VirtualBox UUID allocations from the Pool before the Destroy action\n",
            "removes the UUID from a machine.\n",
            "GENERATED MESSAGE: added missing autodetection logic (#[bio]?) and renamed 'activate' from `when enabled on exit` instead...we were expecting this (because you can't use your child objects\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/inject_test.go b/inject_test.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/inject_test.go\n",
            "+++ b/inject_test.go\n",
            "@@ -696,16 +696,18 @@ func TestInjectMap(t *testing.T) {\n",
            " \t}\n",
            " }\n",
            " \n",
            "+type TypeInjectWit...\n",
            "\n",
            "ACTUAL MESSAGE: use named type in TestInjectMapWithoutPrivate\n",
            "GENERATED MESSAGE: Add new spec that accepts single and multiple fields as well as class keys to validate mapping with\n",
            "multiple values (it is more than the default). Add two additional points of discussion about this which can help\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/config/routes.rb b/config/routes.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/config/routes.rb\n",
            "+++ b/config/routes.rb\n",
            "@@ -1,3 +1,6 @@\n",
            " DealRedemptions::Engine.routes.draw do\n",
            "-  root to: 'redeem#i...\n",
            "\n",
            "ACTUAL MESSAGE: Added root route for welcome and redemptions routing\n",
            "GENERATED MESSAGE: Fix issue where welcome redirects from redresses with redemptions set up and that seems wrong :( Thanks to @cripsforh for spotting it :)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/h2o-py/tests/testdir_algos/gbm/pyunit_bernoulli_synthetic_data_mediumGBM.py b/h2o-py/tests/testdir_algos/gbm/pyunit_bernoulli_synthetic_data_mediumGBM.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a...\n",
            "\n",
            "ACTUAL MESSAGE: make pyunit test a tiny bit more tolerable.\n",
            "GENERATED MESSAGE: Add 'a' in test for scaling tests (#16), replacing `b` and other symbols found in some of the results from this suite as well as the \"slimy\" versions on github\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/db_elasticsearch.js b/lib/db_elasticsearch.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/db_elasticsearch.js\n",
            "+++ b/lib/db_elasticsearch.js\n",
            "@@ -41,7 +41,7 @@ var pool = {\n",
            "         discovery...\n",
            "\n",
            "ACTUAL MESSAGE: Changing replicas to 1 until Vlad fixes the issue with the config\n",
            "GENERATED MESSAGE: Added replications for replicas to the database (#8)\n",
            "We don't want all of our replicas to be unique and random anymore than any other data type that we have available. This is\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/modules/cms/widgets/ComponentList.php b/modules/cms/widgets/ComponentList.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/modules/cms/widgets/ComponentList.php\n",
            "+++ b/modules/cms/widgets/ComponentLi...\n",
            "\n",
            "ACTUAL MESSAGE: Fix for components that support autowiring\n",
            "\n",
            "Removed unneeded null object and call App::make without arguments\n",
            "GENERATED MESSAGE: Don't add the class name in component list (this is an attempt to make sure it's not hiding from view). Now it actually exists and was there for some time without anyone being able figure out\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/test/test_collection.py b/test/test_collection.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/test/test_collection.py\n",
            "+++ b/test/test_collection.py\n",
            "@@ -355,7 +355,7 @@ class TestCollection(unittest...\n",
            "\n",
            "ACTUAL MESSAGE: \"assertNotIn\" unittest method not available in older Python versions\n",
            "GENERATED MESSAGE: tests for #f5 and is not working on pymq1326 using 'borderless data' (#4)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/gromacs/__init__.py b/gromacs/__init__.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/gromacs/__init__.py\n",
            "+++ b/gromacs/__init__.py\n",
            "@@ -231,7 +231,7 @@ import warnings\n",
            " # These warnings should alwa...\n",
            "\n",
            "ACTUAL MESSAGE: set default of LowAccuracyWarning to warn always\n",
            "GENERATED MESSAGE: Remove warnings that do not exist due to variable / name conflicts (#10), so they will no longer be shown as Warning messages when trying code from the source file since these are actually a warning and an\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/Launcher.js b/lib/Launcher.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/Launcher.js\n",
            "+++ b/lib/Launcher.js\n",
            "@@ -85,13 +85,12 @@ class Launcher {\n",
            "     }\n",
            " \n",
            "     // Cleanup as processes exit.\n",
            "...\n",
            "\n",
            "ACTUAL MESSAGE: Fix launcher to not leak event listeners (#<I>)\n",
            "\n",
            "This patch fixes launcher to not leak event listeners.\n",
            "GENERATED MESSAGE: Fix test cases for console shell being closed (#3). * I'm not sure what the real cause is here but it seems to be that bash does nothing when the process exits from a terminal and so\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/lib/plugin.js b/lib/plugin.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/lib/plugin.js\n",
            "+++ b/lib/plugin.js\n",
            "@@ -1,7 +1,8 @@\n",
            " export default (ctx) => {\n",
            "   ctx.$payloadURL = route => {\n",
            "     // TODO r...\n",
            "\n",
            "ACTUAL MESSAGE: set up plugin to generate filename with timestamp\n",
            "GENERATED MESSAGE: Bugfixing error for the remote server in #3970 with no timeout (#<I>)\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/spec/addressable/template_spec.rb b/spec/addressable/template_spec.rb\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/spec/addressable/template_spec.rb\n",
            "+++ b/spec/addressable/template_spec.rb\n",
            "@@ -652,6...\n",
            "\n",
            "ACTUAL MESSAGE: Added an example using a DumbProcessor that doesn't know much about matching, to demonstrate delegation to in-built processing.\n",
            "GENERATED MESSAGE: Fix for multiple tests on the same root (#3).\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/rqalpha/data/base_data_source.py b/rqalpha/data/base_data_source.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/rqalpha/data/base_data_source.py\n",
            "+++ b/rqalpha/data/base_data_source.py\n",
            "@@ -212,7 +21...\n",
            "\n",
            "ACTUAL MESSAGE: fix public fund dividend bug\n",
            "\n",
            "(cherry picked from commit c<I>c5d)\n",
            "GENERATED MESSAGE: Removed unused method for NonSubscribables in RxAlpha::Base data source\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/rostful_node/ros_interface.py b/src/rostful_node/ros_interface.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/rostful_node/ros_interface.py\n",
            "+++ b/src/rostful_node/ros_interface.py\n",
            "@@ -312,7...\n",
            "\n",
            "ACTUAL MESSAGE: fixing removing from dictionary topic_args.\n",
            "GENERATED MESSAGE: Fix the fix with topical names (#39).\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/adapter/mocha.src.js b/adapter/mocha.src.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/adapter/mocha.src.js\n",
            "+++ b/adapter/mocha.src.js\n",
            "@@ -57,9 +57,9 @@ var createMochaReporterConstructor = functi...\n",
            "\n",
            "ACTUAL MESSAGE: Properly handle xit style test skips\n",
            "\n",
            "- xit does not set test.$errors\n",
            "- using test.pending to determine an emtpy (skipped) test\n",
            "  test.pending is set when theres no callback, or for xit\n",
            "GENERATED MESSAGE: add skip test for passing on tests that are already in sync with the app reloading task (#36). #37\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/flask_nav/elements.py b/flask_nav/elements.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/flask_nav/elements.py\n",
            "+++ b/flask_nav/elements.py\n",
            "@@ -5,6 +5,8 @@ from . import get_renderer\n",
            " \n",
            " \n",
            " class Nav...\n",
            "\n",
            "ACTUAL MESSAGE: Make all navigation items have an active attribute.\n",
            "GENERATED MESSAGE: fixing case where no nav element can be rendered for some reason\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/ghost/admin/views/settings.js b/ghost/admin/views/settings.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/ghost/admin/views/settings.js\n",
            "+++ b/ghost/admin/views/settings.js\n",
            "@@ -86,7 +86,11 @@\n",
            "      ...\n",
            "\n",
            "ACTUAL MESSAGE: Adding fade transitions between settings tabs.\n",
            "\n",
            "Closes #<I>\n",
            "- Added a hide and fadeIn() to the render method in Settings.Pane\n",
            "- Any Settings.Pane which overwrites render should now make sure the parent is called\n",
            "- Run through grunt validate, all OK.\n",
            "GENERATED MESSAGE: [Ghost admin] Add FADE In callback to render in case of non active users\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/tests/unit/core/BaseTest.py b/tests/unit/core/BaseTest.py\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/tests/unit/core/BaseTest.py\n",
            "+++ b/tests/unit/core/BaseTest.py\n",
            "@@ -563,9 +563,9 @@ class BaseTes...\n",
            "\n",
            "ACTUAL MESSAGE: Updating test for assigning dict\n",
            "GENERATED MESSAGE: Add an assertion about poring and mapping tests for net.Key().\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/src/Phalcon/DI/Container.php b/src/Phalcon/DI/Container.php\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/src/Phalcon/DI/Container.php\n",
            "+++ b/src/Phalcon/DI/Container.php\n",
            "@@ -11,12 +11,12 @@ use Phalc...\n",
            "\n",
            "ACTUAL MESSAGE: Fix annotations for magic methods definition.\n",
            "GENERATED MESSAGE: Update service method to have expected behavior of the service with respect not only output methods but also methods that are returned in this function as well\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/packages/diffhtml/lib/node/create.js b/packages/diffhtml/lib/node/create.js\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/packages/diffhtml/lib/node/create.js\n",
            "+++ b/packages/diffhtml/lib/node/create....\n",
            "\n",
            "ACTUAL MESSAGE: Docs change\n",
            "\n",
            "Nothing to see here.... move along.\n",
            "GENERATED MESSAGE: Add comment about creating an empty DOM node when copying it to another DOM node while moving its source code around on one of nodes in the DOM tree itself\n",
            "==================================================\n",
            "\n",
            "\n",
            "==================================================\n",
            "TEST ON RANDOM VAL DIFF:\n",
            "DIFF (Truncated):\n",
            "diff --git a/functional_test.go b/functional_test.go\n",
            "index <HASH>..<HASH> 100644\n",
            "--- a/functional_test.go\n",
            "+++ b/functional_test.go\n",
            "@@ -60,7 +60,9 @@ func TestProducingMessages(t *testing.T) {\n",
            " \t}\n",
            " \tde...\n",
            "\n",
            "ACTUAL MESSAGE: Use the ConstantPartitioner in the functional test\n",
            "GENERATED MESSAGE: reconstructed package that doesn't actually work... fix #2\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "def calculate_accuracy(logits, labels):\n",
        "    predictions = torch.argmax(logits, dim=-1) #(batch_size, sequence_length, vocab_size)\n",
        "    correct_predictions = (predictions == labels).float() # (batch_size, sequence_length)\n",
        "    return correct_predictions.mean().item()\n",
        "\n",
        "def get_random_validation_diff(val_df):\n",
        "    # Διαλέγουμε μια τυχαία γραμμή από το validation dataframe\n",
        "    random_row = val_df.sample(n=1).iloc[0]\n",
        "    return random_row['diff'], random_row['message']\n",
        "\n",
        "def generate(model, tokenizer, device,val_df):\n",
        "    model.eval()\n",
        "    val_diff, actual_message = get_random_validation_diff(val_df)\n",
        "    prompt = f\"<|endoftext|>DIFF:\\n{val_diff}\\n\\nCOMMIT MESSAGE:\\n\"\n",
        "    inputs = tokenizer(\n",
        "        prompt, \n",
        "        return_tensors=\"pt\",\n",
        "        return_att \n",
        "        max_length=512, \n",
        "        truncation=True\n",
        "    ).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs, \n",
        "            max_new_tokens=40,\n",
        "            do_sample=True,      \n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.2, \n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id\n",
        "        )\n",
        "\n",
        "    # Αποκωδικοποίηση μόνο της απάντησης\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    generated_message = full_text.split(\"COMMIT MESSAGE:\")[-1].strip()\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"TEST ON RANDOM VAL DIFF:\")\n",
        "    print(f\"DIFF (Truncated):\\n{val_diff[:200]}...\")\n",
        "    print(f\"\\nACTUAL MESSAGE: {actual_message}\")\n",
        "    print(f\"GENERATED MESSAGE: {generated_message}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "    model.train()\n",
        "\n",
        "# --- 2. Training Step ---\n",
        "def train_one_epoch(model, dataloader, optimizer, device, progress_bar, tokenizer,val_df):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "\n",
        "    for i, (x, y) in enumerate(dataloader):\n",
        "        \n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        logits = model(x).logits\n",
        "        loss = nn.CrossEntropyLoss()(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            y.view(-1)\n",
        "        )\n",
        "        acc = calculate_accuracy(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        total_acc += acc\n",
        "\n",
        "        progress_bar.update(1)\n",
        "        progress_bar.set_postfix({\"train_loss\": f\"{loss.item():.4f}\",\"acc\": f\"{acc:.4f}\",\"lr\": f\"{scheduler.get_last_lr()[0]:.2e}\"})\n",
        "\n",
        "\n",
        "        if i > 0 and i % 100 == 0:\n",
        "            generate(model, tokenizer, device,val_df)\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_acc = total_acc / len(dataloader)\n",
        "    return avg_loss,avg_acc\n",
        "\n",
        "# --- 3. Evaluation Step ---\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc=0\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for x, y in dataloader:\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "\n",
        "            logits = model(x).logits\n",
        "            loss = nn.CrossEntropyLoss()(\n",
        "                logits.view(-1, logits.size(-1)),\n",
        "                y.view(-1)\n",
        "            )\n",
        "            total_loss += loss.item()\n",
        "            total_acc  += calculate_accuracy(logits, y)\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    avg_acc = total_acc / len(dataloader)\n",
        "    return avg_loss,avg_acc\n",
        "\n",
        "\n",
        "# --- 4. Main Loop ---\n",
        "def train(model, train_loader, val_loader, optimizer,scheduler, device, tokenizer,epochs,val_df):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    patience = 2\n",
        "    bad_epochs = 0\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch+1}/{epochs}\")\n",
        "\n",
        "        # Train\n",
        "        train_loss,train_acc = train_one_epoch(model, train_loader, optimizer, device, progress_bar, tokenizer,val_df)\n",
        "\n",
        "        # Evaluate\n",
        "        val_loss,val_acc = evaluate(model, val_loader, device)\n",
        "        try:\n",
        "            ppl = math.exp(val_loss)\n",
        "        except OverflowError:\n",
        "            ppl = float('inf')\n",
        "\n",
        "        progress_bar.set_postfix({\n",
        "            \"train_loss\": f\"{train_loss:.4f}\",\n",
        "            \"train_accuracy\": f\"{train_acc:.4f}\",\n",
        "            \"val_loss\": f\"{val_loss:.4f}\",\n",
        "            \"val_accuracy\": f\"{val_acc:.4f}\",\n",
        "            \"PPL\": f\"{ppl:.2f}\"\n",
        "        })\n",
        "        progress_bar.refresh()\n",
        "        progress_bar.close() # Close bar to print new line\n",
        "\n",
        "        # Logging\n",
        "        print(f\"Summary Epoch {epoch+1}: Train Loss: {train_loss:.4f}| Train Accuracy: {train_acc:.4f} \\\n",
        "        |Val Loss: {val_loss:.4f}|Val Accuracy: {val_acc:.4f})| PPL: {ppl:.4f}\")\n",
        "\n",
        "        # Save checkpoints\n",
        "        torch.save(model.state_dict(), f\"{main_path}/gpt2_epoch{epoch+1}.pt\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            bad_epochs = 0\n",
        "            torch.save(model.state_dict(), f\"{main_path}/best_model.pt\")\n",
        "            print(\">>> New best model saved!\")\n",
        "        else:\n",
        "            bad_epochs += 1\n",
        "            print(f\">>> No improvement (bad epochs: {bad_epochs})\")\n",
        "\n",
        "        if bad_epochs >= patience:\n",
        "            print(\"EARLY STOPPING TRIGGERED.\")\n",
        "            break\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "lr = 5e-5\n",
        "epochs = 3\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n",
        "num_training_steps = num_epochs * len(train_loader)\n",
        "num_warmup_steps = int(0.1 * num_training_steps) \n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer, \n",
        "    num_warmup_steps=num_warmup_steps, \n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "train(model, train_loader, val_loader, optimizer, scheduler ,device, tokenizer,epochs,val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e24bfd67",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Το εκπαιδευμένο μοντέλο φορτώθηκε επιτυχώς!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 1. Ορισμός συσκευής και μοντέλου βάσης\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_name = \"gpt2\"\n",
        "\n",
        "# 2. Φόρτωση του tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# 3. Αρχικοποίηση του μοντέλου (Base GPT-2)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# 4. Φόρτωση των δικών σου βαρών από το .pt αρχείο\n",
        "checkpoint_path = 'data/best_model.pt'\n",
        "state_dict = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "# Φόρτωση των βαρών στο μοντέλο\n",
        "model.load_state_dict(state_dict)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Το εκπαιδευμένο μοντέλο φορτώθηκε επιτυχώς!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "585d725d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Increment numbers to use numbers instead of numbers for number of units.\n"
          ]
        }
      ],
      "source": [
        "def generate_commit_message(diff_text, model, tokenizer, device):\n",
        "    model.eval()\n",
        "    \n",
        "    # 1. Καθαρισμός και σωστό Format (ίδιο με το training!)\n",
        "    clean_diff = (diff_text) \n",
        "    prompt = f\"<|endoftext|>DIFF:\\n{clean_diff}\\n\\nCOMMIT MESSAGE:\\n\"\n",
        "    \n",
        "    # 2. Tokenization\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "    \n",
        "    # 3. Παραγωγή (Generation)\n",
        "    with torch.no_grad():\n",
        "        output_tokens = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=50,      \n",
        "            do_sample=True,        \n",
        "            top_p=0.92,             \n",
        "            temperature=0.7,        \n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            no_repeat_ngram_size=2  \n",
        "        )\n",
        "    \n",
        "    # 4. Decoding\n",
        "    full_text = tokenizer.decode(output_tokens[0], skip_special_tokens=True)\n",
        "    \n",
        "    # Επιστρέφουμε μόνο το κομμάτι μετά το \"COMMIT MESSAGE:\"\n",
        "    message = full_text.split(\"COMMIT MESSAGE:\")[-1].strip()\n",
        "    return message\n",
        "\n",
        "test_diff = \"\"\"--- a/app.py\n",
        "+++ b/app.py\n",
        "- def calculate(a, b): return a+b\n",
        "+ def add_numbers(a, b): return a + b\"\"\"\n",
        "print(generate_commit_message(test_diff,model,tokenizer,device))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "DuT6EsaEXBCT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuT6EsaEXBCT",
        "outputId": "5b95ad0c-3560-4c50-8606-07cff9b123fe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-463976673.py:20: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# 1. Setup the App\n",
        "app = FastAPI(title=\"Git Diff to Commit Message API\")\n",
        "\n",
        "# 2. Define Request Schema\n",
        "# This ensures users send valid JSON with a \"diff\" field\n",
        "class DiffRequest(BaseModel):\n",
        "    diff: str\n",
        "    max_tokens: int = 50  # Default value, but user can change it\n",
        "\n",
        "# 3. Global Variables for Model (Loaded on Startup)\n",
        "model = None\n",
        "tokenizer = None\n",
        "device = None\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global model, tokenizer, device\n",
        "\n",
        "    # Configuration\n",
        "    MODEL_PATH = \"best_model.pt\" # Or your specific checkpoint path\n",
        "    BASE_MODEL_NAME = \"gpt2\"     # Needed for the tokenizer configuration\n",
        "\n",
        "    print(\"Loading model and tokenizer...\")\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Load Tokenizer (Use the base gpt2 tokenizer)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_NAME)\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "    # Load Model Structure & Weights\n",
        "    model = AutoModelForCausalLM.from_pretrained(BASE_MODEL_NAME)\n",
        "    model.resize_token_embeddings(len(tokenizer)) # Important if you resized during training\n",
        "\n",
        "    # Load your fine-tuned weights\n",
        "    # map_location ensures it loads even if you move from GPU -> CPU\n",
        "    state_dict = torch.load(MODEL_PATH, map_location=device)\n",
        "    model.load_state_dict(state_dict)\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"Model loaded successfully on {device}!\")\n",
        "\n",
        "# 4. Generation Endpoint\n",
        "@app.post(\"/generate\")\n",
        "async def generate_commit_message(request: DiffRequest):\n",
        "    if not model:\n",
        "        raise HTTPException(status_code=500, detail=\"Model not loaded\")\n",
        "\n",
        "    try:\n",
        "        # Format the input exactly how we trained it\n",
        "        generate_commit_message(DiffRequest,model,tokenizer,device)\n",
        "\n",
        "        return {\n",
        "            \"generated_message\": answer,\n",
        "            \"full_text\": full_text\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# 5. Health Check\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"ok\", \"device\": str(device)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "eUFZzJlx3YxV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUFZzJlx3YxV",
        "outputId": "e8f102cb-5a0f-4ef5-813f-8ddcca9452b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fix(file) fix error handling\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "\n",
        "url = \"http://127.0.0.1:8000/generate\"\n",
        "data = {\"diff\": \"--- a/file.py\\n+++ b/file.py\\n- print('error')\\n+ print('fixed')\"}\n",
        "\n",
        "response = requests.post(url, json=data)\n",
        "print(response.json()['generated_message'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "057e8e4430d64f25b5294903d062369d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_256ec936d1ce4513b17cb09fa055d449",
            "placeholder": "​",
            "style": "IPY_MODEL_5c284bbab3cd481d9168f18c72e92901",
            "value": " 316/316 [03:32&lt;00:00,  1.48it/s, train_loss=1.7154, train_accuracy=0.4933, val_loss=1.5253, val_accuracy=0.5135, PPL=4.60]"
          }
        },
        "0e896eb89da1475d8550f90a03c36442": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc447e673bdc46de8f71f003cd30a914",
            "placeholder": "​",
            "style": "IPY_MODEL_be28821e0f0241079aa0220411328584",
            "value": " 5.67k/? [00:00&lt;00:00, 341kB/s]"
          }
        },
        "15ba200bada44afebfce411f0a08aa51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "17cfad8f10384cfb85a81e2ef100f0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cd40e349b734d60a5b760bf1232ba08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30f6ac4276f547d0913b9b59ebe6bb69",
              "IPY_MODEL_3dc7f099bc69445fbd15e66731ca254c",
              "IPY_MODEL_5b21f33677794182a9d93ba8ebeb87cd"
            ],
            "layout": "IPY_MODEL_f5e05c7e75b9476688eaf110de279cc3"
          }
        },
        "219f986690a6494faa7f03ab475cf437": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "256ec936d1ce4513b17cb09fa055d449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb60b268c3e43cda402c8025694f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59456630863f47d0a2e9a9501fe5e0c0",
              "IPY_MODEL_a653da5d099a4d2e9ab321a502696715",
              "IPY_MODEL_0e896eb89da1475d8550f90a03c36442"
            ],
            "layout": "IPY_MODEL_ed38f0951dd3497da6e36e294ec2c880"
          }
        },
        "30f6ac4276f547d0913b9b59ebe6bb69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76f78b24e1324ae199e4d294a9928a61",
            "placeholder": "​",
            "style": "IPY_MODEL_aa08721eaf914e628c9a9c3889ae8ae5",
            "value": "train.csv:   0%"
          }
        },
        "33745e90c34c497b94fbd995fd47696e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b143e9f25c34c0587c8712e2a0feaaa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dc7f099bc69445fbd15e66731ca254c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf46190f9d2542789096244ff9f159c4",
            "max": 1051789145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15ba200bada44afebfce411f0a08aa51",
            "value": 0
          }
        },
        "48b6e1877b2c49c9bc1b8b9fc51dd53b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c14f83c26ab64ebfb0839a2ef10b663a",
            "placeholder": "​",
            "style": "IPY_MODEL_6f61885f6b7d4a71b8804285cf9802ba",
            "value": "Epoch 1/2: 100%"
          }
        },
        "59456630863f47d0a2e9a9501fe5e0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0a19b53da804d4b8b8457c8ce17351e",
            "placeholder": "​",
            "style": "IPY_MODEL_f55f84e0999740649d5f177be2bf06ea",
            "value": "README.md: "
          }
        },
        "5b21f33677794182a9d93ba8ebeb87cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de406d179c134a649395ac4b5c5e9f07",
            "placeholder": "​",
            "style": "IPY_MODEL_c57e18d56dde4a28a7f54e9bf8a44c6b",
            "value": " 0.00/1.05G [00:00&lt;?, ?B/s]"
          }
        },
        "5c284bbab3cd481d9168f18c72e92901": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f61885f6b7d4a71b8804285cf9802ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76f78b24e1324ae199e4d294a9928a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78961a27e14b41558ee813670c1a7780": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bcb37019bd43e789a8c5c3bbe8fa65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9fcef0e4faa4bbbad3fc33a4809b7ad",
              "IPY_MODEL_db83a6358e34495d82cc4dc8ad2e188e",
              "IPY_MODEL_be789e4225c54bbfb35916dc598fb6ea"
            ],
            "layout": "IPY_MODEL_78961a27e14b41558ee813670c1a7780"
          }
        },
        "93c9bb8fb04442cab7693302f6411458": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c537a0a6f6a4a6390d366511259f673": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a653da5d099a4d2e9ab321a502696715": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d60fe2c0871344828b004a0ca035f233",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_33745e90c34c497b94fbd995fd47696e",
            "value": 1
          }
        },
        "aa08721eaf914e628c9a9c3889ae8ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc447e673bdc46de8f71f003cd30a914": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be28821e0f0241079aa0220411328584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be789e4225c54bbfb35916dc598fb6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b143e9f25c34c0587c8712e2a0feaaa",
            "placeholder": "​",
            "style": "IPY_MODEL_9c537a0a6f6a4a6390d366511259f673",
            "value": " 316/316 [03:28&lt;00:00,  1.71it/s, train_loss=1.3676, train_accuracy=0.5268, val_loss=1.5076, val_accuracy=0.5144, PPL=4.52]"
          }
        },
        "c14f83c26ab64ebfb0839a2ef10b663a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c57e18d56dde4a28a7f54e9bf8a44c6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf46190f9d2542789096244ff9f159c4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d60fe2c0871344828b004a0ca035f233": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "db83a6358e34495d82cc4dc8ad2e188e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dce1237f66864694bbdd786286be4aba",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_219f986690a6494faa7f03ab475cf437",
            "value": 316
          }
        },
        "dce1237f66864694bbdd786286be4aba": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de406d179c134a649395ac4b5c5e9f07": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de90183fff1b4cf4a0862fe1c9fe62ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48b6e1877b2c49c9bc1b8b9fc51dd53b",
              "IPY_MODEL_f262f30aef634b2cb490ed250f2fdde2",
              "IPY_MODEL_057e8e4430d64f25b5294903d062369d"
            ],
            "layout": "IPY_MODEL_f87e68a2b1be4ede9217ecf0ea2e2da9"
          }
        },
        "e30bcadf148a458e97b83fd48158a05d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6c97330b8424ba6ade65aee4920efed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e9fcef0e4faa4bbbad3fc33a4809b7ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30bcadf148a458e97b83fd48158a05d",
            "placeholder": "​",
            "style": "IPY_MODEL_e6c97330b8424ba6ade65aee4920efed",
            "value": "Epoch 2/2: 100%"
          }
        },
        "ed38f0951dd3497da6e36e294ec2c880": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0a19b53da804d4b8b8457c8ce17351e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f262f30aef634b2cb490ed250f2fdde2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93c9bb8fb04442cab7693302f6411458",
            "max": 316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_17cfad8f10384cfb85a81e2ef100f0ce",
            "value": 316
          }
        },
        "f55f84e0999740649d5f177be2bf06ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f5e05c7e75b9476688eaf110de279cc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87e68a2b1be4ede9217ecf0ea2e2da9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
